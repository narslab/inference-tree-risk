
@article{csillik2018identification,
  title = {Identification of {{Citrus Trees}} from {{Unmanned Aerial Vehicle Imagery Using Convolutional Neural Networks}}},
  author = {Csillik, Ovidiu and Cherbini, John and Johnson, Robert and Lyons, Andy and Kelly, Maggi},
  date = {2018-12},
  journaltitle = {Drones},
  volume = {2},
  pages = {39},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  doi = {10.3390/drones2040039},
  url = {https://www.mdpi.com/2504-446X/2/4/39},
  urldate = {2020-12-03},
  abstract = {Remote sensing is important to precision agriculture and the spatial resolution provided by Unmanned Aerial Vehicles (UAVs) is revolutionizing precision agriculture workflows for measurement crop condition and yields over the growing season, for identifying and monitoring weeds and other applications. Monitoring of individual trees for growth, fruit production and pest and disease occurrence remains a high research priority and the delineation of each tree using automated means as an alternative to manual delineation would be useful for long-term farm management. In this paper, we detected citrus and other crop trees from UAV images using a simple convolutional neural network (CNN) algorithm, followed by a classification refinement using superpixels derived from a Simple Linear Iterative Clustering (SLIC) algorithm. The workflow performed well in a relatively complex agricultural environment (multiple targets, multiple size trees and ages, etc.) achieving high accuracy (overall accuracy = 96.24\%, Precision (positive predictive value) = 94.59\%, Recall (sensitivity) = 97.94\%). To our knowledge, this is the first time a CNN has been used with UAV multi-spectral imagery to focus on citrus trees. More of these individual cases are needed to develop standard automated workflows to help agricultural managers better incorporate large volumes of high resolution UAV imagery into agricultural management operations.},
  file = {/home/jbo/Zotero/storage/T7ZKVXX6/Csillik et al. - 2018 - Identification of Citrus Trees from Unmanned Aeria.pdf;/home/jbo/Zotero/storage/BC5YNIAJ/htm.html},
  issue = {4},
  keywords = {citrus,CNN,deep learning,feature extraction,precision agriculture,superpixels,tree identification,UAS},
  langid = {english},
  number = {4}
}

@article{fabijanska2018deepdendro,
  title = {{{DeepDendro}} – {{A}} Tree Rings Detector Based on a Deep Convolutional Neural Network},
  author = {Fabijańska, Anna and Danek, Małgorzata},
  date = {2018-07-01},
  journaltitle = {Computers and Electronics in Agriculture},
  shortjournal = {Computers and Electronics in Agriculture},
  volume = {150},
  pages = {353--363},
  issn = {0168-1699},
  doi = {10.1016/j.compag.2018.05.005},
  url = {http://www.sciencedirect.com/science/article/pii/S0168169918300413},
  urldate = {2020-12-03},
  abstract = {Tree-ring analysis is widely used in many different fields of science. Among others, information carried by annual tree rings allows determining the rates of environmental changes and the timing of events. The analysis of the tree rings requires prior detection of tree-ring boundaries which is traditionally performed manually with the use of stereoscope, a moving table, and a data recorder. This is, however, time-consuming and very cumbersome, especially in the case of long tree-ring series. Several approaches to an automatic detection of tree-ring boundaries exist; however, they use basic image processing techniques. As a result, their accuracy is limited, and their application is restricted mainly to conifer wood where the tree-ring boundaries are clearly defined. There also exists some commercial software, however, none of them is perfect as they fail when applied to the ring-porous wood type. Therefore this paper proposes a DeepDendro approach i.e., an automatic tree-ring boundary detector built upon the U-Net convolutional network. To the authors’ best knowledge this is the first study which applies ConvNets for an automatic detection of tree rings. The performance of the existing approach was tested on the dataset of images of wood cores of three species that represent the ring-porous type of the anatomical structure (Quercus sp., Fraxinus excelsior L., and Ulmus sp.). The testing dataset contained over 2500 of tree-ring boundaries, 96\% of which were determined correctly by the proposed method. The corresponding precision is at the level of 0.97 which confirms that only a few false boundaries were introduced by the DeepDendro approach. The results were obtained automatically without any user interaction.},
  file = {/home/jbo/Zotero/storage/HMP2MW5V/S0168169918300413.html},
  keywords = {Convolutional neural network,Deep learning,Dendrochronology,Tree rings detection,U-Net},
  langid = {english}
}

@article{g.braga2020tree,
  title = {Tree {{Crown Delineation Algorithm Based}} on a {{Convolutional Neural Network}}},
  author = {G. Braga, José R. and Peripato, Vinícius and Dalagnol, Ricardo and P. Ferreira, Matheus and Tarabalka, Yuliya and O. C. Aragão, Luiz E. and F. de Campos Velho, Haroldo and Shiguemori, Elcio H. and Wagner, Fabien H.},
  date = {2020-01},
  journaltitle = {Remote Sensing},
  volume = {12},
  pages = {1288},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  doi = {10.3390/rs12081288},
  url = {https://www.mdpi.com/2072-4292/12/8/1288},
  urldate = {2020-12-03},
  abstract = {Tropical forests concentrate the largest diversity of species on the planet and play a key role in maintaining environmental processes. Due to the importance of those forests, there is growing interest in mapping their components and getting information at an individual tree level to conduct reliable satellite-based forest inventory for biomass and species distribution qualification. Individual tree crown information could be manually gathered from high resolution satellite images; however, to achieve this task at large-scale, an algorithm to identify and delineate each tree crown individually, with high accuracy, is a prerequisite. In this study, we propose the application of a convolutional neural network\&mdash;Mask R-CNN algorithm\&mdash;to perform the tree crown detection and delineation. The algorithm uses very high-resolution satellite images from tropical forests. The results obtained are promising\&mdash;the     R e c a l l    ,     P r e c i s i o n    , and     F 1     score values obtained were were     0.81    ,     0.91    , and     0.86    , respectively. In the study site, the total of tree crowns delineated was     59,062    . These results suggest that this algorithm can be used to assist the planning and conduction of forest inventories. As the algorithm is based on a Deep Learning approach, it can be systematically trained and used for other regions.},
  file = {/home/jbo/Zotero/storage/CATD7A9Z/G. Braga et al. - 2020 - Tree Crown Delineation Algorithm Based on a Convol.pdf;/home/jbo/Zotero/storage/3CGSKS8W/1288.html},
  issue = {8},
  keywords = {deep learning,optical satellite images,tree crown delineation,tropical forests},
  langid = {english},
  number = {8}
}

@online{gao2016degrees,
  title = {Degrees of {{Freedom}} in {{Deep Neural Networks}}},
  author = {Gao, Tianxiang and Jojic, Vladimir},
  date = {2016-06-03},
  url = {http://arxiv.org/abs/1603.09260},
  urldate = {2020-12-02},
  abstract = {In this paper, we explore degrees of freedom in deep sigmoidal neural networks. We show that the degrees of freedom in these models are related to the expected optimism, which is the expected difference between test error and training error. We provide an efficient Monte-Carlo method to estimate the degrees of freedom for multi-class classification methods. We show that the degrees of freedom is less than the parameter count in a simple XOR network. We extend these results to neural nets trained on synthetic and real data and investigate the impact of network’s architecture and different regularization choices. The degrees of freedom in deep networks is dramatically less than the number of parameters. In some real datasets, the number of parameters is several orders of magnitude larger than the degrees of freedom. Further, we observe that for fixed number of parameters, deeper networks have less degrees of freedom exhibiting a regularization-by-depth. Finally, we show that the degrees of freedom of deep neural networks can be used in a model selection criterion. This criterion has comparable performance to crossvalidation with lower computational cost.},
  archivePrefix = {arXiv},
  eprint = {1603.09260},
  eprinttype = {arxiv},
  file = {/home/jbo/Zotero/storage/D2S64IFB/Gao and Jojic - 2016 - Degrees of Freedom in Deep Neural Networks.pdf},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  langid = {english},
  primaryClass = {cs, stat}
}

@article{sharma2019performance,
  title = {Performance Analysis of Deep Learning {{CNN}} Models for Disease Detection in Plants Using Image Segmentation},
  author = {Sharma, Parul and Berwal, Yash Paul Singh and Ghai, Wiqas},
  date = {2019-11-18},
  journaltitle = {Information Processing in Agriculture},
  shortjournal = {Information Processing in Agriculture},
  issn = {2214-3173},
  doi = {10.1016/j.inpa.2019.11.001},
  url = {http://www.sciencedirect.com/science/article/pii/S2214317319301957},
  urldate = {2020-12-02},
  abstract = {Food security for the 7 billion people on earth requires minimizing crop damage by timely detection of diseases. Most deep learning models for automated detection of diseases in plants suffer from the fatal flaw that once tested on independent data, their performance drops significantly. This work investigates a potential solution to this problem by using segmented image data to train the convolutional neural network (CNN) models. As compared to the F-CNN model trained using full images, S-CNN model trained using segmented images more than doubles in performance to 98.6\% accuracy when tested on independent data previously unseen by the models even with 10 disease classes. Not only this, by using tomato plant and target spot disease type as an example, we show that the confidence of self-classification for S-CNN model improves significantly over F-CNN model. This research work brings applicability of automated methods closer to non-experts for timely detection of diseases.},
  file = {/home/jbo/Zotero/storage/DYQ3WXCA/S2214317319301957.html},
  keywords = {Image segmentation,Machine learning,Plant disease detection},
  langid = {english}
}


