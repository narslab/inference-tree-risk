{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image # used for loading images\n",
    "import numpy as np\n",
    "import os # used for navigating to image path\n",
    "import imageio # used for writing images\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from timeit import default_timer as timer\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../python/\")\n",
    "from helpers import *\n",
    "\n",
    "\"\"\"HP Tuning\"\"\"\n",
    "from kerastuner import HyperModel\n",
    "from kerastuner.tuners import RandomSearch\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "import IPython\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import kerastuner as kt\n",
    "from sklearn import ensemble\n",
    "from sklearn import datasets\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NUM_CLASS = 2\n",
    "#NUM_CLASS_PR_PO_IM = 3\n",
    "NUM_CHANNELS = 1\n",
    "RESOLUTION_LIST = [64, 128, 224, 384]\n",
    "SCENARIO_LIST = [\"Pr_Im\", \"PrPo_Im\", \"Pr_PoIm\", \"Pr_Po_Im\"]\n",
    "OPTIMAL_HYPERPARAMETERS_PATH = '../../results/optimal-hyperparameters/'\n",
    "HYPERBAND_MAX_EPOCHS = 3\n",
    "MAX_TRIALS = 3 #0\n",
    "EXECUTIONS_PER_TRIAL = 2 #5\n",
    "HYPERBAND_ITER = 2 #80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"Load numpy output files\"\"\"\n",
    "# images_size64_exp5_Pr_Po_Im = np.load('../../data/tidy/preprocessed_images/size64_exp5_Pr_Po_Im.npy', allow_pickle=True)\n",
    "# images_size64_exp5_Pr_Im = np.load('../../data/tidy/preprocessed_images/size64_exp5_Pr_Im.npy', allow_pickle=True)\n",
    "# images_size64_exp5_PrPo_Im = np.load('../../data/tidy/preprocessed_images/size64_exp5_PrPo_Im.npy', allow_pickle=True)\n",
    "# images_size64_exp5_Pr_PoIm = np.load('../../data/tidy/preprocessed_images/size64_exp5_Pr_PoIm.npy', allow_pickle=True)\n",
    "\n",
    "# images_size128_exp5_Pr_Po_Im = np.load('../../data/tidy/preprocessed_images/size128_exp5_Pr_Po_Im.npy', allow_pickle=True)\n",
    "# images_size128_exp5_Pr_Im = np.load('../../data/tidy/preprocessed_images/size128_exp5_Pr_Im.npy', allow_pickle=True)\n",
    "# images_size128_exp5_PrPo_Im = np.load('../../data/tidy/preprocessed_images/size128_exp5_PrPo_Im.npy', allow_pickle=True)\n",
    "# images_size128_exp5_Pr_PoIm = np.load('../../data/tidy/preprocessed_images/size128_exp5_Pr_PoIm.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dict = dict.fromkeys(RESOLUTION_LIST)\n",
    "for p in RESOLUTION_LIST:\n",
    "    image_dict[p] = dict.fromkeys(SCENARIO_LIST)\n",
    "    for s in SCENARIO_LIST:\n",
    "        image_dict[p][s] = np.load('../../data/tidy/preprocessed_images/size' + str(p) + '_exp5_' + s + '.npy', allow_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_set_64 = [images_size64_exp5_Pr_Im, images_size64_exp5_PrPo_Im, images_size64_exp5_Pr_PoIm, images_size64_exp5_Pr_Po_Im]\n",
    "# image_set_128 = [images_size128_exp5_Pr_Im, images_size128_exp5_PrPo_Im, images_size128_exp5_Pr_PoIm, images_size128_exp5_Pr_Po_Im]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64, 1)\n",
      "(128, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "# input_image_shape_64 = getImageShape(images_size64_exp5_Pr_Im, num_channels = NUM_CHANNELS)\n",
    "# input_image_shape_128 = getImageShape(images_size128_exp5_Pr_Im, num_channels = NUM_CHANNELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNHyperModel(HyperModel):\n",
    "    def __init__(self, input_image_shape, num_classes):\n",
    "        self.input_image_shape = input_image_shape\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def build(self, hp):\n",
    "        model = models.Sequential()\n",
    "\n",
    "        ## Vary kernel size in first Conv Layer between 5 and 7\n",
    "        hp_k_size = hp.Choice('kernel_size', values = [5, 7])\n",
    "\n",
    "        # Tune the number of units in the first and second Dense layers\n",
    "        # Choose an optimal value between 32-512\n",
    "        dense_units_l = hp.Int('units_1', min_value = 32, max_value = 512, step = 32, default = 128)\n",
    "        dense_units_2 = hp.Int('units_2', min_value = 32, max_value = 512, step = 32,  default = 64)  \n",
    "\n",
    "        dropout_rate_1 = hp.Float('dropout_1', min_value = 0.0, max_value = 0.5, step = 0.05)\n",
    "        dropout_rate_2 = hp.Float('dropout_2', min_value = 0.0, max_value = 0.5, step = 0.05)\n",
    "\n",
    "        # Experiment with \"relu\" and \"tanh\" activation f-ns\n",
    "        dense_activation_1 = hp.Choice('activation_1', values = ['relu', 'tanh'], default = 'relu')\n",
    "        dense_activation_2 = hp.Choice('activation_2', values = ['relu', 'tanh'], default = 'relu')\n",
    "\n",
    "        # Tune the learning rate for the optimizer \n",
    "        hp_learning_rate = hp.Float('learning_rate', min_value = 1e-4, max_value = 1e-2, sampling = 'LOG', default = 1e-3) \n",
    "\n",
    "        model.add(layers.Conv2D(filters = 64, kernel_size = hp_k_size, strides = 2, activation=\"relu\", padding=\"same\", input_shape = self.input_image_shape))\n",
    "\n",
    "        model.add(layers.MaxPooling2D(2))\n",
    "        model.add(layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"))\n",
    "        model.add(layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"))\n",
    "        model.add(layers.MaxPooling2D(2))\n",
    "        model.add(layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"))\n",
    "        model.add(layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"))\n",
    "        model.add(layers.MaxPooling2D(2))\n",
    "        model.add(layers.Flatten())\n",
    "\n",
    "        model.add(layers.Dense(units = dense_units_l, activation = dense_activation_1))\n",
    "        model.add(layers.BatchNormalization()) # Networks train faster & converge much more quickly\n",
    "        model.add(layers.Dropout(dropout_rate_1))\n",
    "\n",
    "        model.add(layers.Dense(units = dense_units_2, activation = dense_activation_2))\n",
    "        model.add(layers.Dropout(dropout_rate_2))\n",
    "\n",
    "        model.add(keras.layers.Dense(self.num_classes, activation='softmax'))\n",
    "\n",
    "        # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "        model.compile(optimizer = keras.optimizers.Adam(learning_rate = hp_learning_rate),\n",
    "                    loss = 'categorical_crossentropy',\n",
    "                    metrics = ['accuracy'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# def model_builder_64_2cl(hp):\n",
    "#   model = models.Sequential()\n",
    "  \n",
    "#   ## Vary kernel size in first Conv Layer between 5 and 7\n",
    "#   hp_k_size = hp.Choice('kernel_size', values = [5, 7])\n",
    "  \n",
    "#   # Tune the number of units in the first and second Dense layers\n",
    "#   # Choose an optimal value between 32-512\n",
    "#   hp_units_l1 = hp.Int('units', min_value = 32, max_value = 512, step = 32)\n",
    "#   hp_units_l2 = hp.Int('units', min_value = 32, max_value = 512, step = 32)  \n",
    "    \n",
    "#   dropout_rate_a = hp.Float('dropout', min_value = 0.0, max_value = 0.5, step = 0.1)\n",
    "#   dropout_rate_b = hp.Float('dropout', min_value = 0.0, max_value = 0.5, step = 0.1)\n",
    "    \n",
    "#   # Experiment with \"relu\" and \"tanh\" activation f-ns\n",
    "#   hp_dl1_activation = hp.Choice('activation', values = ['relu', 'tanh'])\n",
    "#   hp_dl2_activation = hp.Choice('activation', values = ['relu', 'tanh'])\n",
    "    \n",
    "#   model.add(layers.Conv2D(filters = 64, kernel_size = hp_k_size, strides = 2, activation=\"relu\", padding=\"same\", input_shape = input_image_shape_64))\n",
    "\n",
    "#   model.add(layers.MaxPooling2D(2))\n",
    "#   model.add(layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"))\n",
    "#   model.add(layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"))\n",
    "#   model.add(layers.MaxPooling2D(2))\n",
    "#   model.add(layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"))\n",
    "#   model.add(layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"))\n",
    "#   model.add(layers.MaxPooling2D(2))\n",
    "#   model.add(layers.Flatten())\n",
    "  \n",
    "#   model.add(layers.Dense(units = hp_units_l1, activation = hp_dl1_activation))\n",
    "#   model.add(layers.BatchNormalization()) # Networks train faster & converge much more quickly\n",
    "#   model.add(layers.Dropout(dropout_rate_a))\n",
    "#   model.add(layers.Dense(units = hp_units_l2, activation = hp_dl2_activation))\n",
    "#   model.add(layers.Dropout(dropout_rate_b))\n",
    "#   model.add(keras.layers.Dense(NUM_CLASS, activation='softmax'))\n",
    "    \n",
    "#   # Tune the learning rate for the optimizer \n",
    "#   # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "#   hp_learning_rate = hp.Choice('learning_rate', values = [1e-2, 1e-3, 1e-4]) \n",
    "#   model.compile(optimizer = keras.optimizers.Adam(learning_rate = hp_learning_rate),\n",
    "#                 loss = keras.losses.CategoricalCrossentropy(from_logits = True), #keras.losses.SparseCategoricalCrossentropy(from_logits = True)\n",
    "#                 metrics = ['accuracy'])\n",
    "#   return model\n",
    "\n",
    "# def model_builder_64_3cl(hp):\n",
    "#   model = models.Sequential()\n",
    "  \n",
    "#   ## Vary kernel size in first Conv Layer between 5 and 7\n",
    "#   hp_k_size = hp.Choice('kernel_size', values = [5, 7])\n",
    "  \n",
    "#   # Tune the number of units in the first and second Dense layers\n",
    "#   # Choose an optimal value between 32-512\n",
    "#   hp_units_l1 = hp.Int('units', min_value = 32, max_value = 512, step = 32)\n",
    "#   hp_units_l2 = hp.Int('units', min_value = 32, max_value = 512, step = 32)  \n",
    "    \n",
    "#   dropout_rate_a = hp.Float('dropout', min_value = 0.0, max_value = 0.5, step = 0.1)\n",
    "#   dropout_rate_b = hp.Float('dropout', min_value = 0.0, max_value = 0.5, step = 0.1)\n",
    "    \n",
    "#   # Experiment with \"relu\" and \"tanh\" activation f-ns\n",
    "#   hp_dl1_activation = hp.Choice('activation', values = ['relu', 'tanh'])\n",
    "#   hp_dl2_activation = hp.Choice('activation', values = ['relu', 'tanh'])\n",
    "    \n",
    "#   model.add(layers.Conv2D(filters = 64, kernel_size = hp_k_size, strides = 2, activation=\"relu\", padding=\"same\", input_shape = input_image_shape_64))\n",
    "\n",
    "#   model.add(layers.MaxPooling2D(2))\n",
    "#   model.add(layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"))\n",
    "#   model.add(layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"))\n",
    "#   model.add(layers.MaxPooling2D(2))\n",
    "#   model.add(layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"))\n",
    "#   model.add(layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"))\n",
    "#   model.add(layers.MaxPooling2D(2))\n",
    "#   model.add(layers.Flatten())\n",
    "  \n",
    "#   model.add(layers.Dense(units = hp_units_l1, activation = hp_dl1_activation))\n",
    "#   model.add(layers.BatchNormalization()) # Networks train faster & converge much more quickly\n",
    "#   model.add(layers.Dropout(dropout_rate_a))\n",
    "#   model.add(layers.Dense(units = hp_units_l2, activation = hp_dl2_activation))\n",
    "#   model.add(layers.Dropout(dropout_rate_b))\n",
    "#   model.add(keras.layers.Dense(NUM_CLASS_PR_PO_IM, activation='softmax'))\n",
    "    \n",
    "#   # Tune the learning rate for the optimizer \n",
    "#   # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "#   hp_learning_rate = hp.Choice('learning_rate', values = [1e-2, 1e-3, 1e-4]) \n",
    "#   model.compile(optimizer = keras.optimizers.Adam(learning_rate = hp_learning_rate),\n",
    "#                 loss = keras.losses.CategoricalCrossentropy(from_logits = True), #keras.losses.SparseCategoricalCrossentropy(from_logits = True)\n",
    "#                 metrics = ['accuracy'])\n",
    "#   return model\n",
    "\n",
    "# def model_builder_128_2cl(hp):\n",
    "#   model = models.Sequential()\n",
    "  \n",
    "#   ## Vary kernel size in first Conv Layer between 5 and 7\n",
    "#   hp_k_size = hp.Choice('kernel_size', values = [5, 7])\n",
    "  \n",
    "#   # Tune the number of units in the first and second Dense layers\n",
    "#   # Choose an optimal value between 32-512\n",
    "#   hp_units_l1 = hp.Int('units', min_value = 32, max_value = 512, step = 32)\n",
    "#   hp_units_l2 = hp.Int('units', min_value = 32, max_value = 512, step = 32)  \n",
    "    \n",
    "#   dropout_rate_a = hp.Float('dropout', min_value = 0.0, max_value = 0.5, step = 0.1)\n",
    "#   dropout_rate_b = hp.Float('dropout', min_value = 0.0, max_value = 0.5, step = 0.1)\n",
    "    \n",
    "#   # Experiment with \"relu\" and \"tanh\" activation f-ns\n",
    "#   hp_dl1_activation = hp.Choice('activation', values = ['relu', 'tanh'])\n",
    "#   hp_dl2_activation = hp.Choice('activation', values = ['relu', 'tanh'])\n",
    "    \n",
    "#   model.add(layers.Conv2D(filters = 64, kernel_size = hp_k_size, strides = 2, activation=\"relu\", padding=\"same\", input_shape = input_image_shape_128))\n",
    "\n",
    "#   model.add(layers.MaxPooling2D(2))\n",
    "#   model.add(layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"))\n",
    "#   model.add(layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"))\n",
    "#   model.add(layers.MaxPooling2D(2))\n",
    "#   model.add(layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"))\n",
    "#   model.add(layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"))\n",
    "#   model.add(layers.MaxPooling2D(2))\n",
    "#   model.add(layers.Flatten())\n",
    "  \n",
    "#   model.add(layers.Dense(units = hp_units_l1, activation = hp_dl1_activation))\n",
    "#   model.add(layers.BatchNormalization()) # Networks train faster & converge much more quickly\n",
    "#   model.add(layers.Dropout(dropout_rate_a))\n",
    "#   model.add(layers.Dense(units = hp_units_l2, activation = hp_dl2_activation))\n",
    "#   model.add(layers.Dropout(dropout_rate_b))\n",
    "#   model.add(keras.layers.Dense(NUM_CLASS, activation='softmax'))\n",
    "    \n",
    "#   # Tune the learning rate for the optimizer \n",
    "#   # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "#   hp_learning_rate = hp.Choice('learning_rate', values = [1e-2, 1e-3, 1e-4]) \n",
    "#   model.compile(optimizer = keras.optimizers.Adam(learning_rate = hp_learning_rate),\n",
    "#                 loss = keras.losses.CategoricalCrossentropy(from_logits = True), #keras.losses.SparseCategoricalCrossentropy(from_logits = True)\n",
    "#                 metrics = ['accuracy'])\n",
    "#   return model\n",
    "\n",
    "# def model_builder_128_3cl(hp):\n",
    "#   model = models.Sequential()\n",
    "  \n",
    "#   ## Vary kernel size in first Conv Layer between 5 and 7\n",
    "#   hp_k_size = hp.Choice('kernel_size', values = [5, 7])\n",
    "  \n",
    "#   # Tune the number of units in the first and second Dense layers\n",
    "#   # Choose an optimal value between 32-512\n",
    "#   hp_units_l1 = hp.Int('units', min_value = 32, max_value = 512, step = 32)\n",
    "#   hp_units_l2 = hp.Int('units', min_value = 32, max_value = 512, step = 32)  \n",
    "    \n",
    "#   dropout_rate_a = hp.Float('dropout', min_value = 0.0, max_value = 0.5, step = 0.1)\n",
    "#   dropout_rate_b = hp.Float('dropout', min_value = 0.0, max_value = 0.5, step = 0.1)\n",
    "    \n",
    "#   # Experiment with \"relu\" and \"tanh\" activation f-ns\n",
    "#   hp_dl1_activation = hp.Choice('activation', values = ['relu', 'tanh'])\n",
    "#   hp_dl2_activation = hp.Choice('activation', values = ['relu', 'tanh'])\n",
    "    \n",
    "#   model.add(layers.Conv2D(filters = 64, kernel_size = hp_k_size, strides = 2, activation=\"relu\", padding=\"same\", input_shape = input_image_shape_128))\n",
    "\n",
    "#   model.add(layers.MaxPooling2D(2))\n",
    "#   model.add(layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"))\n",
    "#   model.add(layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"))\n",
    "#   model.add(layers.MaxPooling2D(2))\n",
    "#   model.add(layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"))\n",
    "#   model.add(layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"))\n",
    "#   model.add(layers.MaxPooling2D(2))\n",
    "#   model.add(layers.Flatten())\n",
    "  \n",
    "#   model.add(layers.Dense(units = hp_units_l1, activation = hp_dl1_activation))\n",
    "#   model.add(layers.BatchNormalization()) # Networks train faster & converge much more quickly\n",
    "#   model.add(layers.Dropout(dropout_rate_a))\n",
    "#   model.add(layers.Dense(units = hp_units_l2, activation = hp_dl2_activation))\n",
    "#   model.add(layers.Dropout(dropout_rate_b))\n",
    "#   model.add(keras.layers.Dense(NUM_CLASS_PR_PO_IM, activation='softmax'))\n",
    "    \n",
    "#   # Tune the learning rate for the optimizer \n",
    "#   # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "#   hp_learning_rate = hp.Choice('learning_rate', values = [1e-2, 1e-3, 1e-4]) \n",
    "#   model.compile(optimizer = keras.optimizers.Adam(learning_rate = hp_learning_rate),\n",
    "#                 loss = keras.losses.CategoricalCrossentropy(from_logits = True), #keras.losses.SparseCategoricalCrossentropy(from_logits = True)\n",
    "#                 metrics = ['accuracy'])\n",
    "#   return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# tuner_64_2cl = kt.Hyperband(model_builder_64_2cl,\n",
    "#                      objective = 'loss', \n",
    "#                      max_epochs = 10,\n",
    "#                      factor = 3,\n",
    "#                      directory = 'opt',\n",
    "#                      project_name = 'imageset_64px_2_class')\n",
    "\n",
    "# tuner_64_3cl = kt.Hyperband(model_builder_64_3cl,\n",
    "#                      objective = 'loss', \n",
    "#                      max_epochs = 10,\n",
    "#                      factor = 3,\n",
    "#                      directory = 'opt',\n",
    "#                      project_name = 'imageset_64px_3_class')\n",
    "\n",
    "# tuner_128_2cl = kt.Hyperband(model_builder_128_2cl,\n",
    "#                      objective = 'loss', \n",
    "#                      max_epochs = 10,\n",
    "#                      factor = 3,\n",
    "#                      directory = 'opt',\n",
    "#                      project_name = 'imageset_128px_2_class')\n",
    "\n",
    "# tuner_128_3cl = kt.Hyperband(model_builder_128_3cl,\n",
    "#                      objective = 'loss', \n",
    "#                      max_epochs = 10,\n",
    "#                      factor = 3,\n",
    "#                      directory = 'opt',\n",
    "#                      project_name = 'imageset_128px_3_class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClearTrainingOutput(tf.keras.callbacks.Callback):\n",
    "    def on_train_end(*args, **kwargs):\n",
    "        IPython.display.clear_output(wait = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Best Hperparamter summary\n",
    "#best_hps_summary = f\"\"\"\n",
    "#The hyperparameter search for classification scenario {CLASSIFICATION_SCENARIO} is complete. The optimal number of units in the first densely-connected\n",
    "#layer is {best_hps.get('units')}. The optimal learning rate for the optimizer\n",
    "#is {best_hps.get('learning_rate')}. The optimal kernel size of the first convolution layer is {best_hps.get('kernel_size')}.\n",
    "#The optimal dropout rate for the optimizer is {best_hps.get('dropout')}. The optimal activation layer for the optimizer is {best_hps.get('activation')}.\n",
    "#\"\"\"\n",
    "#\n",
    "#best_hps_summary_path = model_path + '/best_hyperparameters_summary_scenario_' + CLASSIFICATION_SCENARIO + '.txt'\n",
    "#print(best_hps_summary,  file=open(best_hps_summary_path, 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def createHyperParameterDirectories(image_size):\n",
    "#     hp_path = OPTIMAL_HYPERPARAMETERS_PATH + str(image_size) + '/'\n",
    "#     if not os.path.exists(hp_path):\n",
    "#         os.makedirs(hp_path)\n",
    "#     return\n",
    "\n",
    "# for p in RESOLUTION_LIST:\n",
    "#     createHyperParameterDirectories(p)\n",
    "    \n",
    "# MODEL_PATH_64 = '../../results/models/64/'\n",
    "# MODEL_PATH_128 = '../../results/models/128/'\n",
    "\n",
    "# if not os.path.exists(MODEL_PATH_64): \n",
    "#         os.makedirs(MODEL_PATH_64)\n",
    "# if not os.path.exists(MODEL_PATH_128): \n",
    "#         os.makedirs(MODEL_PATH_128)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizeCNNHyperparameters(scenario, image_size, seed_val = 1, save_results=True):\n",
    "    if scenario==\"Pr_Po_Im\":\n",
    "        NUM_CLASSES = 3\n",
    "    else:\n",
    "        NUM_CLASSES = 2\n",
    "    \n",
    "    hypermodel = CNNHyperModel(input_image_shape = (image_size, image_size, NUM_CHANNELS), num_classes=NUM_CLASSES)\n",
    "    tuner = kt.Hyperband(hypermodel, seed = seed_val, hyperband_iterations = HYPERBAND_ITER, executions_per_trial=EXECUTIONS_PER_TRIAL, max_epochs = HYPERBAND_MAX_EPOCHS,\n",
    "                         objective = 'val_accuracy', overwrite=True, #factor = 3,\n",
    "                         directory = '../../results/opt', project_name = 'tuner_' + str(image_size) + 'px_' + scenario)\n",
    "    training_images_and_labels, test_images_and_labels = splitData(image_dict[image_size][scenario], prop = 0.80, seed_num = 100 + seed_val)\n",
    "    training_images, training_labels = getImageAndLabelArrays(training_images_and_labels)\n",
    "    validation_images, validation_labels = getImageAndLabelArrays(test_images_and_labels)\n",
    "    \n",
    "    tuner.search(training_images, training_labels, validation_data = (validation_images, validation_labels), callbacks = [ClearTrainingOutput()])\n",
    "    best_model = best_model = tuner.get_best_models(num_models=1)[0]\n",
    "    summary = tuner .results_summary()\n",
    "    best_hps = tuner.get_best_hyperparameters(num_trials = 1)[0]\n",
    "    best_hps_dict = best_hps.values\n",
    "    if save_results:\n",
    "        scenario_path = os.path.join(OPTIMAL_HYPERPARAMETERS_PATH, str(image_size), s)\n",
    "        #best_hps_filename = 'hyperparameters.txt'\n",
    "        if not os.path.exists(scenario_path):\n",
    "            os.makedirs(scenario_path)\n",
    "        with open(os.path.join(scenario_path, 'hyperparameters.txt'), 'w') as f:\n",
    "            f.write(json.dumps(best_hps_dict))\n",
    "        with open(os.path.join(scenario_path, 'performance-summary.txt'), 'w') as f:\n",
    "            f.write(json.dumps(summary))            \n",
    "    return(summary, best_model, best_hps_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 60 Complete [00h 04m 27s]\n",
      "val_accuracy: 0.9270588457584381\n",
      "\n",
      "Best val_accuracy So Far: 0.9823529422283173\n",
      "Total elapsed time: 03h 17m 49s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Results summary\n",
      "Results in ../../results/opt/tuner_64px_Pr_Im\n",
      "Showing 10 best trials\n",
      "Objective(name='val_accuracy', direction='max')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "kernel_size: 7\n",
      "units_1: 480\n",
      "units_2: 448\n",
      "dropout_1: 0.1\n",
      "dropout_2: 0.30000000000000004\n",
      "activation_1: relu\n",
      "activation_2: relu\n",
      "learning_rate: 0.0001029562160619873\n",
      "tuner/epochs: 10\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 0.9823529422283173\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "kernel_size: 5\n",
      "units_1: 96\n",
      "units_2: 96\n",
      "dropout_1: 0.2\n",
      "dropout_2: 0.30000000000000004\n",
      "activation_1: relu\n",
      "activation_2: relu\n",
      "learning_rate: 0.0005656677780014923\n",
      "tuner/epochs: 10\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 0.9823529422283173\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "kernel_size: 7\n",
      "units_1: 416\n",
      "units_2: 416\n",
      "dropout_1: 0.2\n",
      "dropout_2: 0.15000000000000002\n",
      "activation_1: relu\n",
      "activation_2: tanh\n",
      "learning_rate: 0.00011465640987948183\n",
      "tuner/epochs: 10\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 0.9811764657497406\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "kernel_size: 7\n",
      "units_1: 128\n",
      "units_2: 192\n",
      "dropout_1: 0.30000000000000004\n",
      "dropout_2: 0.2\n",
      "activation_1: tanh\n",
      "activation_2: relu\n",
      "learning_rate: 0.00018524901137433573\n",
      "tuner/epochs: 10\n",
      "tuner/initial_epoch: 4\n",
      "tuner/bracket: 1\n",
      "tuner/round: 1\n",
      "tuner/trial_id: a7ec0bff20b382b0dc6e12eeab3bd74d\n",
      "Score: 0.9811764657497406\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "kernel_size: 7\n",
      "units_1: 128\n",
      "units_2: 320\n",
      "dropout_1: 0.25\n",
      "dropout_2: 0.30000000000000004\n",
      "activation_1: relu\n",
      "activation_2: tanh\n",
      "learning_rate: 0.00017582232810420384\n",
      "tuner/epochs: 10\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 0.977647066116333\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "kernel_size: 5\n",
      "units_1: 256\n",
      "units_2: 224\n",
      "dropout_1: 0.45\n",
      "dropout_2: 0.25\n",
      "activation_1: relu\n",
      "activation_2: relu\n",
      "learning_rate: 0.0003647863570162414\n",
      "tuner/epochs: 10\n",
      "tuner/initial_epoch: 4\n",
      "tuner/bracket: 2\n",
      "tuner/round: 2\n",
      "tuner/trial_id: 51ae0fd9aa2cffc459e70783fff9796e\n",
      "Score: 0.9729411900043488\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "kernel_size: 7\n",
      "units_1: 288\n",
      "units_2: 192\n",
      "dropout_1: 0.2\n",
      "dropout_2: 0.25\n",
      "activation_1: tanh\n",
      "activation_2: tanh\n",
      "learning_rate: 0.0014172041528226799\n",
      "tuner/epochs: 10\n",
      "tuner/initial_epoch: 4\n",
      "tuner/bracket: 1\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 21efffa8a1a9ac5f9d48c9f6531d3a88\n",
      "Score: 0.9694117605686188\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "kernel_size: 5\n",
      "units_1: 64\n",
      "units_2: 288\n",
      "dropout_1: 0.05\n",
      "dropout_2: 0.0\n",
      "activation_1: relu\n",
      "activation_2: relu\n",
      "learning_rate: 0.003098269932407016\n",
      "tuner/epochs: 10\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 0.9682352840900421\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "kernel_size: 7\n",
      "units_1: 448\n",
      "units_2: 384\n",
      "dropout_1: 0.30000000000000004\n",
      "dropout_2: 0.30000000000000004\n",
      "activation_1: relu\n",
      "activation_2: relu\n",
      "learning_rate: 0.0019236959117182775\n",
      "tuner/epochs: 10\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 0.9658823609352112\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "kernel_size: 7\n",
      "units_1: 128\n",
      "units_2: 192\n",
      "dropout_1: 0.30000000000000004\n",
      "dropout_2: 0.2\n",
      "activation_1: tanh\n",
      "activation_2: relu\n",
      "learning_rate: 0.00018524901137433573\n",
      "tuner/epochs: 4\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 1\n",
      "tuner/round: 0\n",
      "Score: 0.9564706087112427\n"
     ]
    }
   ],
   "source": [
    "s,b,h = optimizeCNNHyperparameters(\"Pr_Im\", 64, save_results=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x7fcf234a9f40>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    for i in RESOLUTION_LIST:\n",
    "        for s in SCENARIO_LIST:     \n",
    "            print(\"Beginning search for scenario: \" + s)\n",
    "            optimizeCNNHyperparameters(scenario, image_size, seed_num = 1, save_results=True):\n",
    "            print(\"Search for scenario: \" + s + \" is complete.\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def best_model_fit(tuner, model_path):\n",
    "#     tuner.search(training_images, training_labels, epochs = 10, validation_data = (validation_images, validation_labels), callbacks = [ClearTrainingOutput()])\n",
    "#     best_hps = tuner.get_best_hyperparameters(num_trials = 1)[0]\n",
    "#     best_hps_dict = best_hps.values\n",
    "#     best_model = tuner.hypermodel.build(best_hps)\n",
    "#     best_model.fit(training_images, training_labels, epochs=10, validation_data=(validation_images, validation_labels))\n",
    "#     best_model_json = best_model.to_json()\n",
    "#     scenario_path = os.path.join(model_path, scenario_list[k])\n",
    "#     attr_path = os.path.join(scenario_path, 'attributes')\n",
    "#     best_hps_path = 'hyperparameters_' + '.txt'\n",
    "#     #model_summary_path = 'model_summary_' + '.txt'\n",
    "#     #model_to_json_path = 'model_to_json_' + '.txt'\n",
    "#     if not os.path.exists(attr_path):\n",
    "#         os.makedirs(attr_path)\n",
    "#     with open(os.path.join(attr_path, best_hps_path), 'w') as f:\n",
    "#         f.write(json.dumps(best_hps_dict))\n",
    "#     with open(os.path.join(attr_path, model_summary_path), 'w') as f:\n",
    "#         best_model.summary(print_fn=lambda x: f.write(x + '\\n'))\n",
    "#     with open(os.path.join(attr_path, model_to_json_path), 'w') as f:\n",
    "#         f.write(json.dumps(best_model_json))\n",
    "    # best_model.save(scenario_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = 0\n",
    "# for is_64 in image_set_64:\n",
    "#     training_images_and_labels, test_images_and_labels = splitData(is_64, prop = 0.80, seed_num = 1)\n",
    "#     training_images, training_labels = getImageAndLabelArrays(training_images_and_labels)\n",
    "#     validation_images, validation_labels = getImageAndLabelArrays(test_images_and_labels)\n",
    "#     print(\"Beginning search for scenario: \" + scenario_list[k])\n",
    "#     if(is_64 != images_size64_exp5_Pr_Po_Im):\n",
    "#         best_model_fit(tuner_64_2cl, MODEL_PATH_64)\n",
    "#     else:\n",
    "#         best_model_fit(tuner_64_3cl, MODEL_PATH_64)\n",
    "#     print(\"Search for scenario: \" + scenario_list[k] + \" is complete.\")\n",
    "#     k=k+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# k = 0\n",
    "# for is_128 in image_set_128:\n",
    "#     training_images_and_labels, test_images_and_labels = splitData(is_128, prop = 0.80, seed_num = 1)\n",
    "#     training_images, training_labels = getImageAndLabelArrays(training_images_and_labels)\n",
    "#     validation_images, validation_labels = getImageAndLabelArrays(test_images_and_labels)\n",
    "#     print(\"Beginning search for scenario: \" + scenario_list[k])\n",
    "#     if(is_128 != images_size128_exp5_Pr_Po_Im):\n",
    "#         best_model_fit(tuner_128_2cl, MODEL_PATH_128)\n",
    "#     else:\n",
    "#         best_model_fit(tuner_128_3cl, MODEL_PATH_128)\n",
    "#     print(\"Search for scenario: \" + scenario_list[k] + \" is complete.\")\n",
    "#     k=k+1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
