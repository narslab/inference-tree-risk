{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "import pandas as pd\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.ticker as tkr\n",
    "\n",
    "from matplotlib import cm\n",
    "from tf_keras_vis.gradcam import Gradcam\n",
    "from tf_keras_vis.saliency import Saliency\n",
    "from tf_keras_vis.utils import normalize\n",
    "\n",
    "import json\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../python/\")\n",
    "from helpers import *\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Globals\n",
    "NUM_CHANNELS = 3\n",
    "IMAGE_WIDTH_LIST = [189]#, 252, 336]\n",
    "SCENARIO_LIST = [\"Pr_Po_Im\"] #, PrPo_Im \"Pr_Im\", \"Pr_PoIm\", \"Pr_Po_Im\"]\n",
    "NUM_EPOCHS = 20\n",
    "SAVED_MODEL_DIR = '../../results/models/'\n",
    "MODEL_PERFORMANCE_METRICS_DIR = '../../results/model-performance/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image sets\n",
    "IMAGE_SETS_SQUARE_TRAIN = createResolutionScenarioImageDict(IMAGE_WIDTH_LIST, SCENARIO_LIST, train=True, rectangular = False)\n",
    "IMAGE_SETS_SQUARE_TEST = createResolutionScenarioImageDict(IMAGE_WIDTH_LIST, SCENARIO_LIST, train=False, rectangular = False)\n",
    "IMAGE_SETS_RECT_TRAIN = createResolutionScenarioImageDict(IMAGE_WIDTH_LIST, SCENARIO_LIST, train=True, rectangular = True)\n",
    "IMAGE_SETS_RECT_TEST = createResolutionScenarioImageDict(IMAGE_WIDTH_LIST, SCENARIO_LIST, train=False, rectangular = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metrics(Callback):\n",
    "    def __init__(self, val_data):#, batch_size = 64):\n",
    "        super().__init__()\n",
    "        self.validation_data = val_data\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.val_f1s = []\n",
    "        self.val_recalls = []\n",
    "        self.val_precisions = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        xVal, yVal = self.validation_data\n",
    "        val_pred = np.argmax(np.asarray(self.model.predict(xVal)), axis=1)\n",
    "        val_true = np.argmax(yVal, axis=1)        \n",
    "        _val_f1 = f1_score(val_true, val_pred, average='macro', zero_division = 0)\n",
    "        _val_precision = precision_score(val_true, val_pred, average='macro', zero_division = 0)\n",
    "        _val_recall = recall_score(val_true, val_pred, average='macro', zero_division = 0)\n",
    "\n",
    "        self.val_f1s.append(_val_f1)\n",
    "        self.val_recalls.append(_val_recall)\n",
    "        self.val_precisions.append(_val_precision)\n",
    "        logs[\"val_f1\"] = _val_f1\n",
    "        logs[\"val_recall\"] = _val_recall\n",
    "        logs[\"val_precision\"] = _val_precision\n",
    "        print('— val_f1: %f — val_precision: %f — val_recall %f' %(_val_f1, _val_precision, _val_recall))\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testCNN(image_width, image_height, num_channels=3):\n",
    "    image_shape = (image_width, image_height, num_channels)\n",
    "    print('Image shape: ', image_shape)\n",
    "    model = models.Sequential()\n",
    "\n",
    "    model.add(layers.Conv2D(filters = 64, kernel_size = 5, strides = 2, activation=\"relu\", padding=\"same\", \n",
    "        input_shape = image_shape ))\n",
    "\n",
    "    model.add(layers.MaxPooling2D(2))\n",
    "    model.add(layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"))\n",
    "    model.add(layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"))\n",
    "    model.add(layers.MaxPooling2D(2))\n",
    "    model.add(layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"))\n",
    "    model.add(layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"))\n",
    "    model.add(layers.MaxPooling2D(2))\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    model.add(layers.Dense(units = 408, activation = 'relu'))\n",
    "    model.add(layers.BatchNormalization()) # Networks train faster & converge much more quickly\n",
    "    model.add(layers.Dropout(.3))\n",
    "\n",
    "    model.add(layers.Dense(units = 408, activation = 'relu'))\n",
    "    model.add(layers.Dropout(.3))\n",
    "\n",
    "    model.add(layers.Dense(3, activation='softmax'))\n",
    "\n",
    "    # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "    model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = .001), #learning_rate = hp_learning_rate not defined\n",
    "                loss = 'categorical_crossentropy',\n",
    "                metrics = ['accuracy'])\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModelWithDetailedMetrics(image_width, scenario, num_epochs = 10, trial_seed = 1, rectangular = True, testing = True): \n",
    "    # IMAGES (former approach)\n",
    "    # training_images_and_labels, test_images_and_labels = splitData(image_sets[image_size][scenario], prop = 0.8, seed_num = trial_seed)\n",
    "    # training_images, training_labels = getImageAndLabelArrays(training_images_and_labels)\n",
    "    # test_images, test_labels = getImageAndLabelArrays(test_images_and_labels)\n",
    "    if rectangular:\n",
    "        image_height = getRectangularImageHeight(image_width)\n",
    "    else:\n",
    "        image_height = image_width\n",
    "\n",
    "    class_labels = getClassLabels(scenario)\n",
    "    print(\"Class labels:\", class_labels)\n",
    "\n",
    "    if rectangular==True:\n",
    "        image_dictionary_train = IMAGE_SETS_RECT_TRAIN\n",
    "        image_dictionary_test = IMAGE_SETS_RECT_TEST\n",
    "    else:\n",
    "        image_dictionary_train = IMAGE_SETS_SQUARE_TRAIN\n",
    "        image_dictionary_test = IMAGE_SETS_SQUARE_TEST\n",
    "\n",
    "        \n",
    "    training_images = np.array([x[0] for x in image_dictionary_train[image_width][scenario]]) ## TOD)\n",
    "    training_labels = np.array([x[1] for x in image_dictionary_train[image_width][scenario]]) \n",
    "    test_images = np.array([x[0] for x in image_dictionary_test[image_width][scenario]]) ## TOD)\n",
    "    test_labels = np.array([x[1] for x in image_dictionary_test[image_width][scenario]]) \n",
    "#     training_images = np.array([np.expand_dims(x[0],axis=2) for x in image_dictionary_train[image_width][scenario]]) ## TOD)\n",
    "#     training_labels = np.array([x[1] for x in image_dictionary_train[image_width][scenario]]) \n",
    "#     test_images = np.array([np.expand_dims(x[0],axis=2) for x in image_dictionary_test[image_width][scenario]]) ## TOD)\n",
    "#     test_labels = np.array([x[1] for x in image_dictionary_test[image_width][scenario]]) \n",
    "\n",
    "    print(\"Number of class training images:\", training_labels.sum(axis=0), \"total: \", training_labels.sum())\n",
    "    print(\"Number of class test images:\", test_labels.sum(axis=0), \"total: \", test_labels.sum())\n",
    "    \n",
    "    # CALLBACKS\n",
    "    model_metrics = Metrics(val_data=(test_images, test_labels))\n",
    "    early_stopping = EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True)\n",
    "    \n",
    "    # INIT MODEL AND PARAMS, FIT\n",
    "    K.clear_session()\n",
    "    #input_shape = (image_size, image_size, NUM_CHANNELS) ## shape of images\n",
    "    if testing:\n",
    "        model = testCNN(image_width, image_height, num_channels=NUM_CHANNELS)\n",
    "    else:\n",
    "        model = constructOptBaseCNN(image_width, image_height, scenario, num_channels = NUM_CHANNELS)    ## get model\n",
    "        opt_learning_rate = getOptCNNHyperparams(image_width, image_height, scenario)['learning_rate']    ## learning rate\n",
    "        opt = tf.keras.optimizers.Adam(learning_rate = opt_learning_rate)    \n",
    "    reset_weights(model) # re-initialize model weights\n",
    "    if testing:\n",
    "        model.compile(loss='categorical_crossentropy', metrics =  ['accuracy'])     ## compile and fit\n",
    "    else:\n",
    "        model.compile(loss='categorical_crossentropy', optimizer = opt, metrics =  ['accuracy'])     ## compile and fit\n",
    "    hist = model.fit(training_images, training_labels, batch_size = 32, epochs = num_epochs, verbose=1, \n",
    "                     validation_data=(test_images, test_labels),\n",
    "                     callbacks = [model_metrics]) #, early_stopping])     \n",
    "    \n",
    "    # SAVE MODEL, SUMMARY AND PERFORMANCE\n",
    "    if testing == True:\n",
    "        model_name = \"test-opt-cnn-\" + scenario + \"-w-\" + str(image_width) + \"-px-h-\" + str(image_height) + \"-px\"\n",
    "    else:\n",
    "        model_name = \"opt-cnn-\" + scenario + \"-w-\" +str(image_width) + \"-px-h-\" + str(image_height) + \"-px\"\n",
    "    model_folder = \"model\"\n",
    "    if not os.path.exists(SAVED_MODEL_DIR):  \n",
    "        os.makedirs(SAVED_MODEL_DIR)\n",
    "    model.save(os.path.join(SAVED_MODEL_DIR, model_name, model_folder))     ## Save model summary\n",
    "    #print(os.path.join(SAVED_MODEL_DIR, model_name, \"summary.txt\"))\n",
    "    with open(os.path.join(SAVED_MODEL_DIR, model_name, \"summary.txt\"), 'w') as f:\n",
    "        model.summary(print_fn=lambda x: f.write(x + '\\n'))\n",
    "    with open(os.path.join(SAVED_MODEL_DIR, model_name, \"history.txt\"), 'w') as f:\n",
    "        f.write(json.dumps(hist.history))    \n",
    "   \n",
    "    # ANALYZE PERFORMANCE AND SAVE OUTPUTS\n",
    "    y_pred = np.argmax(model.predict(test_images), axis=-1)     ## Params\n",
    "    ## Classification report\n",
    "    report = classification_report(np.argmax(test_labels, axis=-1), y_pred, zero_division=0,\n",
    "                                   labels = np.arange(len(class_labels)), target_names=class_labels, output_dict=True)\n",
    "    print(\"Classification report for scenario \" + scenario + \", width: \" + str(image_width) + \", height: \" + str(image_height) + \":\")\n",
    "    report = pd.DataFrame(report).transpose().round(2)\n",
    "    if not os.path.exists('../../results/classification-reports/'):  \n",
    "        os.makedirs('../../results/classification-reports/')\n",
    "    classification_report_suffix = scenario + \"-w-\" + str(image_width) + \"-h-\" + str(image_height) + \"px.csv\"\n",
    "    if testing == True:\n",
    "        report.to_csv(\"../../results/classification-reports/test-opt-classification-report-\" + classification_report_suffix)\n",
    "    else:\n",
    "        report.to_csv(\"../../results/classification-reports/opt-classification-report-\" + classification_report_suffix)        \n",
    "    print(report)\n",
    "    \n",
    "    ## Confusion matrix\n",
    "    con_mat = tf.math.confusion_matrix(labels=np.argmax(test_labels, axis=-1), predictions=y_pred).numpy()\n",
    "    con_mat_norm = np.around(con_mat.astype('float') / con_mat.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "    con_mat_df = pd.DataFrame(con_mat_norm, index = class_labels, columns = class_labels)\n",
    "    #print(\"Confusion matrix for scenario \" + scenario + \", resolution: \" + str(image_size) + \":\")\n",
    "    #print(con_mat_df)\n",
    "    figure = plt.figure()#figsize=(4, 4))    ## Confusion matrix heatmap\n",
    "    ax = sns.heatmap(con_mat_df, annot=True, cmap=plt.cm.Blues, fmt='g', cbar = False, annot_kws={\"size\": 16})\n",
    "    #figure.tight_layout()\n",
    "    plt.ylabel('True',fontsize=16)\n",
    "    ax.set_yticklabels(class_labels,va='center',fontsize=14)\n",
    "    ax.set_xticklabels(class_labels, ha='center',fontsize=14)\n",
    "    plt.xlabel('Predicted',fontsize=16)\n",
    "    #plt.show()\n",
    "    file_suffix =  scenario + \"-w-\" + str(image_width) + \"-px-h-\" + str(image_height) + \"-px.png\"\n",
    "    if testing == True:\n",
    "        con_mat_heatmap_file = \"../../figures/test-opt-confusion-matrix-\" +  file_suffix\n",
    "    else:\n",
    "        con_mat_heatmap_file = \"../../figures/opt-confusion-matrix-\" +  file_suffix\n",
    "    figure.savefig(con_mat_heatmap_file, dpi=180)#, bbox_inches='tight')\n",
    "    return(model, hist) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getScenarioModelPerformance(width = 189, num_epochs = 15, seed_val = 1, rect_boolean = True, test_boolean = True):\n",
    "    df = pd.DataFrame()\n",
    "    if rect_boolean:\n",
    "        height = getRectangularImageHeight(width)\n",
    "    else:\n",
    "        height = width\n",
    "    for s in SCENARIO_LIST:\n",
    "        m, h = trainModelWithDetailedMetrics(width, s, num_epochs, trial_seed = seed_val, \n",
    "            rectangular = rect_boolean, testing = test_boolean)\n",
    "        #visualizeCNN(m, s, width, images_per_class = 4, trial_seed = seed_val, testing = test_boolean)       \n",
    "        perf = pd.DataFrame.from_dict(h.history)\n",
    "        perf[['Scenario']] = s\n",
    "        perf['epoch'] = perf.index + 1\n",
    "        df = df.append(perf, ignore_index=True)\n",
    "        #del m\n",
    "    if test_boolean == True:\n",
    "        df_filename = \"../../results/test-opt-cnn-performance-metrics-summary-w-\" + str(width) + \"-px-h\" + str(height) + \"-px.csv\"\n",
    "    else:\n",
    "        df_filename = \"../../results/opt-cnn-performance-metrics-summary-w-\" + str(width) + \"-px-h\" + str(height) +  \"-px.csv\"\n",
    "    df.to_csv(df_filename)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class labels: ['Improbable', 'Possible', 'Probable']\n",
      "Number of class training images: [740 208 116] total:  1064\n",
      "Number of class test images: [89 26 18] total:  133\n",
      "Image shape:  (189, 189, 3)\n",
      "34/34 [==============================] - 28s 788ms/step - loss: 1.1699 - accuracy: 0.5565 - val_loss: 8.3061 - val_accuracy: 0.6692\n",
      "— val_f1: 0.267267 — val_precision: 0.223058 — val_recall 0.333333\n",
      "INFO:tensorflow:Assets written to: ../../results/models/test-opt-cnn-Pr_Po_Im-w-189-px-h-189-px\\model\\assets\n",
      "Classification report for scenario Pr_Po_Im, width: 189, height: 189:\n",
      "              precision  recall  f1-score  support\n",
      "Improbable         0.67    1.00      0.80    89.00\n",
      "Possible           0.00    0.00      0.00    26.00\n",
      "Probable           0.00    0.00      0.00    18.00\n",
      "accuracy           0.67    0.67      0.67     0.67\n",
      "macro avg          0.22    0.33      0.27   133.00\n",
      "weighted avg       0.45    0.67      0.54   133.00\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['Scenario'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-88585b3d9186>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgetScenarioModelPerformance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m189\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrect_boolean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_boolean\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-7-e6a0855e6dff>\u001b[0m in \u001b[0;36mgetScenarioModelPerformance\u001b[1;34m(width, num_epochs, seed_val, rect_boolean, test_boolean)\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;31m#visualizeCNN(m, s, width, images_per_class = 4, trial_seed = seed_val, testing = test_boolean)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mperf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mperf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Scenario'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0mperf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'epoch'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mperf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mperf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   2933\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2934\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2935\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2936\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2937\u001b[0m             \u001b[1;31m# set column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_setitem_array\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   2963\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2964\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2965\u001b[1;33m                 indexer = self.loc._get_listlike_indexer(\n\u001b[0m\u001b[0;32m   2966\u001b[0m                     \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2967\u001b[0m                 )[1]\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1550\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1551\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1552\u001b[1;33m         self._validate_read_indexer(\n\u001b[0m\u001b[0;32m   1553\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1554\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1638\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmissing\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1639\u001b[0m                 \u001b[0maxis_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1640\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1641\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1642\u001b[0m             \u001b[1;31m# We (temporarily) allow for some missing keys with .loc, except in\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['Scenario'], dtype='object')] are in the [columns]\""
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "getScenarioModelPerformance(width=189, num_epochs=1, seed_val = 2, rect_boolean = False, test_boolean=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
