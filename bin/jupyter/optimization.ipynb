{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image # used for loading images\n",
    "import numpy as np\n",
    "import os # used for navigating to image path\n",
    "import imageio # used for writing images\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from timeit import default_timer as timer\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../python/\")\n",
    "from helpers import *\n",
    "\n",
    "\"\"\"HP Tuning\"\"\"\n",
    "from kerastuner import HyperModel\n",
    "from kerastuner.tuners import RandomSearch\n",
    "\n",
    "import IPython\n",
    "#from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import kerastuner as kt\n",
    "from sklearn import ensemble\n",
    "from sklearn import datasets\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CHANNELS = 1\n",
    "RESOLUTION_LIST = [64, 128, 224, 384]\n",
    "SCENARIO_LIST = [\"Pr_Im\", \"PrPo_Im\", \"Pr_PoIm\", \"Pr_Po_Im\"]\n",
    "OPTIMAL_HYPERPARAMETERS_PATH = '../../results/optimal-hyperparameters/'\n",
    "HYPERBAND_MAX_EPOCHS = 10 #10\n",
    "EXECUTIONS_PER_TRIAL = 3 #5\n",
    "HYPERBAND_ITER = 5 #80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dict = dict.fromkeys(RESOLUTION_LIST)\n",
    "for p in RESOLUTION_LIST:\n",
    "    image_dict[p] = dict.fromkeys(SCENARIO_LIST)\n",
    "    for s in SCENARIO_LIST:\n",
    "        image_dict[p][s] = np.load('../../data/tidy/preprocessed_images/size' + str(p) + '_exp5_' + s + '.npy', allow_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNHyperModel(HyperModel):\n",
    "    def __init__(self, input_image_shape, num_classes):\n",
    "        self.input_image_shape = input_image_shape\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def build(self, hp):\n",
    "        model = models.Sequential()\n",
    "\n",
    "        ## Vary kernel size in first Conv Layer between 5 and 7\n",
    "        hp_k_size = hp.Choice('kernel_size', values = [5, 7])\n",
    "\n",
    "        # Tune the number of units in the first and second Dense layers\n",
    "        # Choose an optimal value between 32-512\n",
    "        dense_units_l = hp.Int('units_1', min_value = 32, max_value = 512, step = 32, default = 128)\n",
    "        dense_units_2 = hp.Int('units_2', min_value = 32, max_value = 512, step = 32,  default = 64)  \n",
    "\n",
    "        dropout_rate_1 = hp.Float('dropout_1', min_value = 0.0, max_value = 0.5, step = 0.05)\n",
    "        dropout_rate_2 = hp.Float('dropout_2', min_value = 0.0, max_value = 0.5, step = 0.05)\n",
    "\n",
    "        # Experiment with \"relu\" and \"tanh\" activation f-ns\n",
    "        dense_activation_1 = hp.Choice('activation_1', values = ['relu', 'tanh'], default = 'relu')\n",
    "        dense_activation_2 = hp.Choice('activation_2', values = ['relu', 'tanh'], default = 'relu')\n",
    "\n",
    "        # Tune the learning rate for the optimizer \n",
    "        hp_learning_rate = hp.Float('learning_rate', min_value = 1e-4, max_value = 1e-2, sampling = 'LOG', default = 1e-3) \n",
    "\n",
    "        model.add(layers.Conv2D(filters = 64, kernel_size = hp_k_size, strides = 2, activation=\"relu\", padding=\"same\", input_shape = self.input_image_shape))\n",
    "\n",
    "        model.add(layers.MaxPooling2D(2))\n",
    "        model.add(layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"))\n",
    "        model.add(layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"))\n",
    "        model.add(layers.MaxPooling2D(2))\n",
    "        model.add(layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"))\n",
    "        model.add(layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"))\n",
    "        model.add(layers.MaxPooling2D(2))\n",
    "        model.add(layers.Flatten())\n",
    "\n",
    "        model.add(layers.Dense(units = dense_units_l, activation = dense_activation_1))\n",
    "        model.add(layers.BatchNormalization()) # Networks train faster & converge much more quickly\n",
    "        model.add(layers.Dropout(dropout_rate_1))\n",
    "\n",
    "        model.add(layers.Dense(units = dense_units_2, activation = dense_activation_2))\n",
    "        model.add(layers.Dropout(dropout_rate_2))\n",
    "\n",
    "        model.add(layers.Dense(self.num_classes, activation='softmax'))\n",
    "\n",
    "        # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "        model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = hp_learning_rate),\n",
    "                    loss = 'categorical_crossentropy',\n",
    "                    metrics = ['accuracy'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClearTrainingOutput(tf.keras.callbacks.Callback):\n",
    "    def on_train_end(*args, **kwargs):\n",
    "        IPython.display.clear_output(wait = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizeCNNHyperparameters(scenario, image_size, seed_val = 1, save_results=True):\n",
    "    if scenario==\"Pr_Po_Im\":\n",
    "        NUM_CLASSES = 3\n",
    "    else:\n",
    "        NUM_CLASSES = 2\n",
    "    \n",
    "    hypermodel = CNNHyperModel(input_image_shape = (image_size, image_size, NUM_CHANNELS), num_classes=NUM_CLASSES)\n",
    "    tuner = kt.Hyperband(hypermodel, seed = seed_val, hyperband_iterations = HYPERBAND_ITER, executions_per_trial=EXECUTIONS_PER_TRIAL, max_epochs = HYPERBAND_MAX_EPOCHS,\n",
    "                         objective = 'val_accuracy', overwrite=True, #factor = 3,\n",
    "                         directory = '../../results/opt', project_name = 'tuner_' + str(image_size) + 'px_' + scenario)\n",
    "    training_images_and_labels, test_images_and_labels = splitData(image_dict[image_size][scenario], prop = 0.80, seed_num = 100 + seed_val)\n",
    "    training_images, training_labels = getImageAndLabelArrays(training_images_and_labels)\n",
    "    validation_images, validation_labels = getImageAndLabelArrays(test_images_and_labels)\n",
    "    \n",
    "    console_printout = tuner.search(training_images, training_labels, validation_data = (validation_images, validation_labels), callbacks = [ClearTrainingOutput()])\n",
    "    #best_model = best_model = tuner.get_best_models(num_models=1)[0]\n",
    "    results = tuner.results_summary()\n",
    "    best_hps = tuner.get_best_hyperparameters(num_trials = 1)[0]\n",
    "    best_hps_dict = best_hps.values\n",
    "    if save_results:\n",
    "        scenario_path = os.path.join(OPTIMAL_HYPERPARAMETERS_PATH, str(image_size), s)\n",
    "        #best_hps_filename = 'hyperparameters.txt'\n",
    "        if not os.path.exists(scenario_path):\n",
    "            os.makedirs(scenario_path)\n",
    "        with open(os.path.join(scenario_path, 'hyperparameters.txt'), 'w') as f:\n",
    "            f.write(json.dumps(best_hps_dict))\n",
    "        with open(os.path.join(scenario_path, 'performance-summary.txt'), 'w') as f:\n",
    "            f.write(json.dumps(summary))            \n",
    "    return #(console_printout, summary, best_hps_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#s,b,h = optimizeCNNHyperparameters(\"Pr_Im\", 64, save_results=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    for i in RESOLUTION_LIST:\n",
    "        for s in SCENARIO_LIST:     \n",
    "            print(\"Beginning search for scenario: \" + s)\n",
    "            optimizeCNNHyperparameters(s, i, seed_val = 1, save_results = True)\n",
    "            print(\"Search for scenario: \" + s + \" is complete.\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
