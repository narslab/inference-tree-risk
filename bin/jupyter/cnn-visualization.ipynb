{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "import pandas as pd\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.ticker as tkr\n",
    "\n",
    "from matplotlib import cm\n",
    "from tf_keras_vis.gradcam import Gradcam\n",
    "from tf_keras_vis.saliency import Saliency\n",
    "from tf_keras_vis.utils import normalize\n",
    "\n",
    "import json\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../python/\")\n",
    "from helpers import *\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "#from sklearn.preprocessing import OrdinalEncoder\n",
    "#enc = OrdinalEncoder()\n",
    "\n",
    "#from contextlib import redirect_stdout\n",
    "\n",
    "# Globals\n",
    "NUM_CHANNELS = 1\n",
    "RESOLUTION_LIST = [128] # 64, 128] #, 224, 384]\n",
    "SCENARIO_LIST = [\"PrPo_Im\"] #, \"Pr_Im\", \"Pr_PoIm\", \"Pr_Po_Im\"]\n",
    "NUM_EPOCHS = 20\n",
    "SAVED_MODEL_DIR = '../../results/models/'\n",
    "MODEL_PERFORMANCE_METRICS_DIR = '../../results/model-performance/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotGradCAM(model, scenario, image_size, images_per_class = 4, trial_seed = 1, testing=True):\n",
    "    image_sets = createResolutionScenarioImageDict(RESOLUTION_LIST, SCENARIO_LIST)\n",
    "    \n",
    "#     ALT: use train_test_split\n",
    "    training_images,validation_images,training_labels,validation_labels =  train_test_split(np.array([np.expand_dims(x[0],axis=2) for x in image_sets[image_size][scenario]]), \n",
    "                np.array([x[1] for x in image_sets[image_size][scenario]]), stratify= np.array([x[1] for x in image_sets[image_size][scenario]]), test_size=.2, random_state = trial_seed)\n",
    "\n",
    "#     training_images_and_labels, test_images_and_labels = splitData(image_sets[image_size][scenario], prop = 0.8, seed_num = trial_seed)\n",
    "#     training_images, training_labels = getImageAndLabelArrays(training_images_and_labels)\n",
    "#     validation_images, validation_labels = getImageAndLabelArrays(test_images_and_labels)\n",
    "    class_labels = getClassLabels(scenario)\n",
    "    print(\"Class labels:\", class_labels)\n",
    "    print(training_labels.sum(axis=0)) # Sum by row\n",
    "    print(validation_labels.sum(axis=0))    \n",
    "    \n",
    "    \n",
    "    # GRAD CAM\n",
    "    random.seed(trial_seed)\n",
    "    # Randomly sample images from each class\n",
    "    random_image_selection_class_0 = random.sample([i for i, j in enumerate(validation_labels) if np.argmax(j) == 0], k = images_per_class)    \n",
    "    random.seed(trial_seed+1)\n",
    "    random_image_selection_class_1 = random.sample([i for i, j in enumerate(validation_labels) if np.argmax(j) == 1], k = images_per_class)\n",
    "    assert validation_labels[random_image_selection_class_0].mean(axis=0)[0] == 1 #assert that indices of class 0 labels are correct\n",
    "    assert validation_labels[random_image_selection_class_1].mean(axis=0)[1] == 1 #assert that indices of class 1 labels are correct\n",
    "    cam_list = random_image_selection_class_0 + random_image_selection_class_1 # join lists of indices in both classes\n",
    "    if scenario==\"Pr_Po_Im\": # in 3-class case\n",
    "        random.seed(trial_seed+2)\n",
    "        random_image_selection_class_2 = random.sample([i for i, j in enumerate(validation_labels) if np.argmax(j) == 2], k = images_per_class)    \n",
    "        cam_list = cam_list + random_image_selection_class_2 # join to prior list of class 0 and class 1\n",
    "        assert validation_labels[random_image_selection_class_2].mean(axis=0)[2] == 1 #assert that indices of class 2 labels are correct\n",
    "\n",
    "    def loss(output):\n",
    "        \"\"\"Returns score corresponding to class of given image index\"\"\"                                       \n",
    "        print(output)\n",
    "        loss_list = [output[i][j] for i, j in enumerate([np.argmax(j) for j in validation_labels[cam_list] ])]\n",
    "        return loss_list\n",
    "\n",
    "    # Model_modifier function required for gradcam\n",
    "    def model_modifier(m):\n",
    "        \"\"\"Remove softmax activation of last layer in model\"\"\"\n",
    "        m.layers[-1].activation = tf.keras.activations.linear\n",
    "        return m\n",
    "\n",
    "    # subset validation images to use for gradcam\n",
    "    print(\"List of indices from validation images:\", cam_list)\n",
    "    gradcam_images = validation_images[cam_list] #tf.convert_to_tensor(validation_images[cam_list], dtype= tf.float32)\n",
    "    print(\"Shape of gradcam image array:\", gradcam_images.shape)\n",
    "    print([np.argmax(j) for j in validation_labels[cam_list] ])\n",
    "\n",
    "    # Create Gradcam object\n",
    "    gradcam = Gradcam(model, model_modifier = model_modifier)#, clone=False)\n",
    "\n",
    "    # Generate heatmap with GradCAM\n",
    "    subplot_args = { 'nrows': len(class_labels), 'ncols': images_per_class, 'figsize': (3*images_per_class,3*len(class_labels)), \n",
    "                    'subplot_kw': {'xticks': [], 'yticks': []} }    \n",
    "    cam = gradcam(loss, gradcam_images, penultimate_layer = -1)\n",
    "    cam = normalize(cam)\n",
    "    print(len(cam))\n",
    "    f, ax = plt.subplots(**subplot_args)\n",
    "    f.set_facecolor(\"white\")\n",
    "    image_counter = 0\n",
    "    for i, label in enumerate(class_labels):\n",
    "        ax[i,0].set_ylabel(label, fontsize=14)\n",
    "        for j in np.arange(images_per_class):\n",
    "            print(i, j, image_counter)\n",
    "            heatmap = np.uint8(cm.jet(cam[image_counter])[..., :3] * 255)\n",
    "            ax[i, j].imshow(np.squeeze(gradcam_images[image_counter], axis=2), cmap='gist_gray') #remove axes of length one from gradcam_images\n",
    "            #print(heatmap.shape)\n",
    "            ax[i, j].imshow(heatmap, cmap='jet', alpha=0.5) # overlay\n",
    "            image_counter += 1\n",
    "    plt.tight_layout()\n",
    "    #plt.show()\n",
    "    if testing==True:\n",
    "        f.savefig(\"../../figures/test-opt-gradcam-\" + scenario + \"-\" + str(image_size) + \"-px-\" + str(images_per_class) + \"-images.png\")\n",
    "    else:\n",
    "        f.savefig(\"../../figures/opt-gradcam-\" + scenario + \"-\" + str(image_size) + \"-px-\" + str(images_per_class) + \"-images.png\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = models.load_model('../../results/models/opt-cnn-PrPo_Im-128-px/model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image_sets = createResolutionScenarioImageDict(RESOLUTION_LIST, SCENARIO_LIST)\n",
    "plotGradCAM(m, \"PrPo_Im\", 128, images_per_class = 2, trial_seed = 1,  testing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotSaliency(model, scenario, image_size, images_per_class = 4, trial_seed = 1, saliency=False, testing=True):\n",
    "    training_images_and_labels, test_images_and_labels = splitData(image_sets[image_size][scenario], prop = 0.8, seed_num = trial_seed)\n",
    "    training_images, training_labels = getImageAndLabelArrays(training_images_and_labels)\n",
    "    validation_images, validation_labels = getImageAndLabelArrays(test_images_and_labels)\n",
    "    class_labels = getClassLabels(scenario)\n",
    "    print(\"Class labels:\", class_labels)\n",
    "    print(training_labels.sum(axis=0))\n",
    "    print(validation_labels.sum(axis=0))    \n",
    "    \n",
    "    # GRAD CAM\n",
    "    random.seed(trial_seed)\n",
    "    # Randomly sample images from each class\n",
    "    random_image_selection_class_0 = random.sample([i for i, j in enumerate(validation_labels) if np.argmax(j) == 0], k = images_per_class)    \n",
    "    random.seed(trial_seed+1)\n",
    "    random_image_selection_class_1 = random.sample([i for i, j in enumerate(validation_labels) if np.argmax(j) == 1], k = images_per_class)\n",
    "    assert validation_labels[random_image_selection_class_0].mean(axis=0)[0] == 1 #assert that indices of class 0 labels are correct\n",
    "    assert validation_labels[random_image_selection_class_1].mean(axis=0)[1] == 1 #assert that indices of class 1 labels are correct\n",
    "    cam_list = random_image_selection_class_0 + random_image_selection_class_1 # join lists of indices in both classes\n",
    "    if scenario==\"Pr_Po_Im\": # in 3-class case\n",
    "        random.seed(trial_seed+2)\n",
    "        random_image_selection_class_2 = random.sample([i for i, j in enumerate(validation_labels) if np.argmax(j) == 2], k = images_per_class)    \n",
    "        cam_list = cam_list + random_image_selection_class_2 # join to prior list of class 0 and class 1\n",
    "        assert validation_labels[random_image_selection_class_2].mean(axis=0)[2] == 1 #assert that indices of class 2 labels are correct\n",
    "    # subset validation images to use for gradcam\n",
    "    print(\"List of indices from validation images:\", cam_list)\n",
    "    gradcam_images = validation_images[cam_list] #tf.convert_to_tensor(validation_images[cam_list], dtype= tf.float32)\n",
    "    print(\"Shape of gradcam image array:\", gradcam_images.shape)\n",
    "    print([np.argmax(j) for j in validation_labels[cam_list] ])\n",
    "\n",
    "    subplot_args = { 'nrows': len(class_labels), 'ncols': images_per_class, 'figsize': (3*images_per_class,3*len(class_labels)), \n",
    "                    'subplot_kw': {'xticks': [], 'yticks': []} }    \n",
    "\n",
    "    saliency = Saliency(model, model_modifier=model_modifier)#                    clone=False)\n",
    "\n",
    "    # Generate saliency map with smoothing that reduce noise by adding noise\n",
    "    saliency_map = saliency(loss, gradcam_images, \n",
    "                            smooth_samples=20, # The number of calculating gradients iterations.\n",
    "                            smooth_noise=0.20) # noise spread level.\n",
    "    saliency_map = normalize(saliency_map)\n",
    "    #image_titles = class_labels\n",
    "    f, ax = plt.subplots(**subplot_args)\n",
    "    f.set_facecolor(\"white\")\n",
    "    image_counter = 0\n",
    "    for i, label in enumerate(class_labels):\n",
    "        ax[i,0].set_ylabel(label, fontsize=14)\n",
    "        for j in np.arange(images_per_class):\n",
    "            print(i, j, image_counter)\n",
    "            ax[i, j].imshow(saliency_map[image_counter], cmap='jet', alpha=0.5) # overlay\n",
    "            image_counter += 1\n",
    "    plt.tight_layout()\n",
    "    #plt.show()\n",
    "    if testing == True:\n",
    "        f.savefig(\"../../figures/test-opt-saliency-\" + scenario + \"-\" + str(image_size) + \"-px-\" + str(images_per_class) + \"-images.png\")\n",
    "    else:\n",
    "        f.savefig(\"../../figures/opt-saliency-\" + scenario + \"-\" + str(image_size) + \"-px-\" + str(images_per_class) + \"-images.png\")\n",
    "return\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_keras_vis.activation_maximization import ActivationMaximization\n",
    "\n",
    "def model_modifier(m):\n",
    "    \"\"\"Remove softmax activation of last layer in model\"\"\"\n",
    "    m.layers[-1].activation = tf.keras.activations.linear\n",
    "    return m\n",
    "\n",
    "activation_maximization = ActivationMaximization(m,\n",
    "                                                 model_modifier)\n",
    "                                                 \n",
    "def loss(output):\n",
    "    return output[:, 0]\n",
    "\n",
    "\n",
    "from tf_keras_vis.utils.callbacks import Print\n",
    "\n",
    "activation = activation_maximization(loss,\n",
    "                                     callbacks=[Print(interval=50)])\n",
    "image = activation[0].astype(np.uint8)\n",
    "\n",
    "subplot_args = { 'nrows': 1, 'ncols': 1, 'figsize': (3, 3),\n",
    "                 'subplot_kw': {'xticks': [], 'yticks': []} }\n",
    "f, ax = plt.subplots(**subplot_args)\n",
    "ax.set_title('Ouzel', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
