{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# This script explores CNN model performance based on training image resolution.\n",
    "# We test the following training image sizes:\n",
    "# 64 x 64, 128 x 128, 224 x 224, 384 x 384\n",
    "\n",
    "import numpy as np\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "import pandas as pd\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import json\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../python/\")\n",
    "from helpers import *\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "#from sklearn.preprocessing import OrdinalEncoder\n",
    "#enc = OrdinalEncoder()\n",
    "\n",
    "# Globals\n",
    "NUM_CHANNELS = 1\n",
    "RESOLUTION_LIST = [64,128] # 64, 128] #, 224, 384]\n",
    "SCENARIO_LIST = [\"Pr_Im\", \"PrPo_Im\", \"Pr_PoIm\", \"Pr_Po_Im\"]\n",
    "NUM_MODEL_RUNS = 10\n",
    "NUM_EPOCHS = 10\n",
    "SCENARIO_PERFORMANCE_METRICS_DIR = '../../results/models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_sets = createResolutionScenarioImageDict(RESOLUTION_LIST, SCENARIO_LIST)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Metrics2 modified from https://stackoverflow.com/a/61856587/3023033\n",
    "class Metrics2(Callback):\n",
    "    def __init__(self, val_data):#, batch_size = 64):\n",
    "        super().__init__()\n",
    "        self.validation_data = val_data\n",
    "        #self.batch_size = batch_size\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        #print(self.validation_data)\n",
    "        self.val_f1s = []\n",
    "        self.val_recalls = []\n",
    "        self.val_precisions = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        #batches = len(self.validation_data)\n",
    "        #total = batches * self.batch_size\n",
    "\n",
    "        #val_pred = np.zeros((total,1))\n",
    "        #val_true = np.zeros((total))\n",
    "\n",
    "        xVal, yVal = self.validation_data\n",
    "        val_pred = np.argmax(np.asarray(self.model.predict(xVal)), axis=1)\n",
    "        val_true = np.argmax(yVal, axis=1)        \n",
    "        #val_pred = np.squeeze(val_pred)\n",
    "        _val_f1 = f1_score(val_true, val_pred, average='weighted', zero_division = 0)\n",
    "        _val_precision = precision_score(val_true, val_pred, average='weighted', zero_division = 0)\n",
    "        _val_recall = recall_score(val_true, val_pred, average='weighted', zero_division = 0)\n",
    "\n",
    "        self.val_f1s.append(_val_f1)\n",
    "        self.val_recalls.append(_val_recall)\n",
    "        self.val_precisions.append(_val_precision)\n",
    "        print('— val_f1: %f — val_precision: %f — val_recall %f' %(_val_f1, _val_precision, _val_recall))\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModelWithDetailedMetrics(image_size, scenario, num_epochs = 10, trial_seed = 1): \n",
    "    \n",
    "    # IMAGES\n",
    "    training_images_and_labels, test_images_and_labels = splitData(image_sets[image_size][scenario], prop = 0.7, seed_num = trial_seed)\n",
    "    training_images, training_labels = getImageAndLabelArrays(training_images_and_labels)\n",
    "    validation_images, validation_labels = getImageAndLabelArrays(test_images_and_labels)\n",
    "    \n",
    "    # CALLBACKS\n",
    "    model_metrics = Metrics2(val_data=(validation_images, validation_labels))\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n",
    "    # batch_training_histories = Histories()\n",
    "    \n",
    "    # INIT MODEL AND PARAMS\n",
    "    K.clear_session()\n",
    "    ## shape of images\n",
    "    input_shape = (image_size, image_size, NUM_CHANNELS)\n",
    "    ## learning rate\n",
    "    opt_learning_rate = getOptCNNHyperparams(image_size, scenario)['learning_rate']\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate = opt_learning_rate)\n",
    "    ## get model\n",
    "    model = constructBaseCNN(image_size, scenario, num_channels = NUM_CHANNELS)\n",
    "    reset_weights(model) # re-initialize model weights\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',  optimizer = opt, metrics =  ['accuracy']) \n",
    "\n",
    "    hist = model.fit(training_images, training_labels, batch_size = 32, epochs = num_epochs, verbose=1, \n",
    "                     validation_data=(validation_images, validation_labels),\n",
    "                     callbacks = [model_metrics, early_stopping]) #, callbacks=[batch_training_histories])\n",
    "    \n",
    "    \n",
    "    # SAVE MODEL \n",
    "    model_name = \"opt-cnn-\" + scenario + \"-\" +str(image_size) + \"-px\"\n",
    "    model_folder = \"model\"\n",
    "    model.save(os.path.join(SCENARIO_PERFORMANCE_METRICS_DIR, model_name, model_folder))\n",
    "    filename = \"performance.txt\"    \n",
    "    \n",
    "    # ANALYZE PERFORMANCE AND SAVE OUTPUTS\n",
    "    ## Params\n",
    "    class_labels = getClassLabels(scenario)\n",
    "    y_pred = np.argmax(model.predict(validation_images), axis=-1) \n",
    "    ## Classification report\n",
    "    report = classification_report(np.argmax(validation_labels, axis=-1), y_pred, zero_division=0,\n",
    "                                   labels = np.arange(len(class_labels)), target_names=class_labels)\n",
    "    print(\"Classification report for scenario \" + scenario + \", resolution: \" + str(image_size) + \":\")\n",
    "    print(report)\n",
    "    ## Confusion matrix\n",
    "    con_mat = tf.math.confusion_matrix(labels=np.argmax(validation_labels, axis=-1), predictions=y_pred).numpy()\n",
    "    con_mat_norm = np.around(con_mat.astype('float') / con_mat.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "    con_mat_df = pd.DataFrame(con_mat, index = class_labels, columns = class_labels)\n",
    "    print(\"Confusion matrix for scenario \" + scenario + \", resolution: \" + str(image_size) + \":\")\n",
    "    print(con_mat_df)\n",
    "    ## Confusion matrix heatmap\n",
    "    figure = plt.figure()#figsize=(4, 4))\n",
    "    ax = sns.heatmap(con_mat_df, annot=True, cmap=plt.cm.Blues, fmt='g')\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True')\n",
    "    ax.set_yticklabels(class_labels, ha='center')\n",
    "    ax.set_xticklabels(class_labels, ha='center')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.show()\n",
    "    return(hist) #performance_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /usr/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /usr/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /usr/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:758 train_step\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    /usr/lib/python3.9/site-packages/tensorflow/python/keras/engine/compile_utils.py:387 update_state\n        self.build(y_pred, y_true)\n    /usr/lib/python3.9/site-packages/tensorflow/python/keras/engine/compile_utils.py:317 build\n        self._metrics = nest.map_structure_up_to(y_pred, self._get_metric_objects,\n    /usr/lib/python3.9/site-packages/tensorflow/python/util/nest.py:1159 map_structure_up_to\n        return map_structure_with_tuple_paths_up_to(\n    /usr/lib/python3.9/site-packages/tensorflow/python/util/nest.py:1257 map_structure_with_tuple_paths_up_to\n        results = [\n    /usr/lib/python3.9/site-packages/tensorflow/python/util/nest.py:1258 <listcomp>\n        func(*args, **kwargs) for args in zip(flat_path_gen, *flat_value_gen)\n    /usr/lib/python3.9/site-packages/tensorflow/python/util/nest.py:1161 <lambda>\n        lambda _, *values: func(*values),  # Discards the path arg.\n    /usr/lib/python3.9/site-packages/tensorflow/python/keras/engine/compile_utils.py:418 _get_metric_objects\n        return [self._get_metric_object(m, y_t, y_p) for m in metrics]\n    /usr/lib/python3.9/site-packages/tensorflow/python/keras/engine/compile_utils.py:418 <listcomp>\n        return [self._get_metric_object(m, y_t, y_p) for m in metrics]\n    /usr/lib/python3.9/site-packages/tensorflow/python/keras/engine/compile_utils.py:437 _get_metric_object\n        metric_obj = metrics_mod.get(metric)\n    /usr/lib/python3.9/site-packages/tensorflow/python/keras/metrics.py:3490 get\n        return deserialize(str(identifier))\n    /usr/lib/python3.9/site-packages/tensorflow/python/keras/metrics.py:3446 deserialize\n        return deserialize_keras_object(\n    /usr/lib/python3.9/site-packages/tensorflow/python/keras/utils/generic_utils.py:377 deserialize_keras_object\n        raise ValueError(\n\n    ValueError: Unknown metric function: _val_precision\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-0371ef81ada2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainModelWithDetailedMetrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Pr_Po_Im\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-38-45cb81a13f9b>\u001b[0m in \u001b[0;36mtrainModelWithDetailedMetrics\u001b[0;34m(image_size, scenario, num_epochs, trial_seed)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_val_precision'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     hist = model.fit(training_images, training_labels, batch_size = 32, epochs = num_epochs, verbose=1, \n\u001b[0m\u001b[1;32m     27\u001b[0m                      \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                      callbacks = [model_metrics, early_stopping]) #, callbacks=[batch_training_histories])\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    723\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 725\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    726\u001b[0m             *args, **kwds))\n\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3194\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3195\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3196\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3197\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3198\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /usr/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /usr/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:758 train_step\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    /usr/lib/python3.9/site-packages/tensorflow/python/keras/engine/compile_utils.py:387 update_state\n        self.build(y_pred, y_true)\n    /usr/lib/python3.9/site-packages/tensorflow/python/keras/engine/compile_utils.py:317 build\n        self._metrics = nest.map_structure_up_to(y_pred, self._get_metric_objects,\n    /usr/lib/python3.9/site-packages/tensorflow/python/util/nest.py:1159 map_structure_up_to\n        return map_structure_with_tuple_paths_up_to(\n    /usr/lib/python3.9/site-packages/tensorflow/python/util/nest.py:1257 map_structure_with_tuple_paths_up_to\n        results = [\n    /usr/lib/python3.9/site-packages/tensorflow/python/util/nest.py:1258 <listcomp>\n        func(*args, **kwargs) for args in zip(flat_path_gen, *flat_value_gen)\n    /usr/lib/python3.9/site-packages/tensorflow/python/util/nest.py:1161 <lambda>\n        lambda _, *values: func(*values),  # Discards the path arg.\n    /usr/lib/python3.9/site-packages/tensorflow/python/keras/engine/compile_utils.py:418 _get_metric_objects\n        return [self._get_metric_object(m, y_t, y_p) for m in metrics]\n    /usr/lib/python3.9/site-packages/tensorflow/python/keras/engine/compile_utils.py:418 <listcomp>\n        return [self._get_metric_object(m, y_t, y_p) for m in metrics]\n    /usr/lib/python3.9/site-packages/tensorflow/python/keras/engine/compile_utils.py:437 _get_metric_object\n        metric_obj = metrics_mod.get(metric)\n    /usr/lib/python3.9/site-packages/tensorflow/python/keras/metrics.py:3490 get\n        return deserialize(str(identifier))\n    /usr/lib/python3.9/site-packages/tensorflow/python/keras/metrics.py:3446 deserialize\n        return deserialize_keras_object(\n    /usr/lib/python3.9/site-packages/tensorflow/python/keras/utils/generic_utils.py:377 deserialize_keras_object\n        raise ValueError(\n\n    ValueError: Unknown metric function: _val_precision\n"
     ]
    }
   ],
   "source": [
    "h = trainModelWithDetailedMetrics(64, \"Pr_Po_Im\", num_epochs = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.8506993055343628, 0.42776286602020264],\n",
       " 'val_loss': [0.739395260810852, 0.5800334215164185]}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h[0].history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.9144983291625977, 0.5433341860771179, 0.30878946185112],\n",
       " 'val_loss': [0.9429678320884705, 0.8512963652610779, 0.8752889633178711]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#h.history\n",
    "h.history\n",
    "#pd.DataFrame.from_dict(h.history).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = final.predict(X_test)\n",
    "# y_indx = np.argmax(y_test_new, axis = 1)\n",
    "# pred_indx = np.argmax(y_pred, axis = 1)\n",
    "# print(classification_report(y_indx, pred_indx))\n",
    "\n",
    "# def main(num_trials = NUM_MODEL_RUNS):\n",
    "#     if not os.path.exists(RESOLUTION_PERFORMANCE_METRICS_DIR): # check if 'tidy/preprocessed_images' subdirectory does not exist\n",
    "#         os.makedirs(RESOLUTION_PERFORMANCE_METRICS_DIR) # if not, create it    \n",
    "#     for s in SCENARIO_LIST:\n",
    "#         for p in RESOLUTION_LIST:\n",
    "#             for i in range(num_trials):\n",
    "#                 print(\"Conducting performance test: Scenario - \" + s + \"; Resolution - \" + str(p) + \"px; Trial - \" + str(i+1))\n",
    "#                 scenario_performance_dict = testResolutionScenarioPerformance(p, s, num_epochs = NUM_EPOCHS, trial_seed = 1 + i) #ultimately should be averaged across trials       \n",
    "#                 scenario_filename = \"scenario_resolution_performance_\" + s + str(p) + \"px_trial_\" + str(i+1) + \".txt\"\n",
    "#                 with open(os.path.join(RESOLUTION_PERFORMANCE_METRICS_DIR, scenario_filename), 'w') as f:\n",
    "#                    f.write(json.dumps(scenario_performance_dict )) # use `json.loads` to do the reverse)\n",
    "#     return\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()\n",
    "\n",
    "\n",
    "# predictions = model.predict_classes(x_val)\n",
    "# predictions = predictions.reshape(1,-1)[0]\n",
    "\n",
    "# print(classification_report(y_val, predictions, target_names = ['Rugby (Class 0)','Soccer (Class 1)']))v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "#     metrics = [\n",
    "#     tfma.metrics.ExampleCount(name='example_count'),\n",
    "#     tfma.metrics.WeightedExampleCount(name='weighted_example_count'),\n",
    "#     tf.keras.metrics.SparseCategoricalCrossentropy(\n",
    "#         name='sparse_categorical_crossentropy'),\n",
    "#     tf.keras.metrics.SparseCategoricalAccuracy(name='accuracy'),\n",
    "#     tf.keras.metrics.Precision(name='precision', top_k=1),\n",
    "#     #tf.keras.metrics.Precision(name='precision', top_k=3),\n",
    "#     tf.keras.metrics.Recall(name='recall', top_k=1),\n",
    "#     #tf.keras.metrics.Recall(name='recall', top_k=3),\n",
    "#     tfma.metrics.MultiClassConfusionMatrixPlot(\n",
    "#         name='multi_class_confusion_matrix_plot'),]\n",
    "#     metrics_specs = tfma.metrics.specs_from_metrics(metrics)\n",
    "#     metrics_specs = tfma.metrics.specs_from_metrics(metrics,\n",
    "#         aggregate=tfma.AggregationOptions(\n",
    "#             macro_average=True, class_weights={i: 1.0 for i in range(3)}))\n",
    "\n",
    "\n",
    "    # performance_dict = {}    \n",
    "    # performance_dict['scenario'] = scenario\n",
    "    # performance_dict['image_size'] = image_size\n",
    "    # performance_dict['metrics'] = hist.history\n",
    "    # performance_dict['best_val_accuracy'] = np.max(hist.history['val_accuracy'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
