{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script explores CNN model performance based on training image resolution.\n",
    "# We test the following training image sizes:\n",
    "# 64 x 64, 128 x 128, 224 x 224, 384 x 384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from timeit import default_timer as timer\n",
    "import matplotlib.pyplot as plt\n",
    "import pydot\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_size64_exp5_Pr_Po_Im = np.load('../../data/tidy/preprocessed_images/size64_exp5_Pr_Po_Im.npy', allow_pickle=True)\n",
    "images_size64_exp5_Pr_Im = np.load('../../data/tidy/preprocessed_images/size64_exp5_Pr_Im.npy', allow_pickle=True)\n",
    "images_size64_exp5_PrPo_Im = np.load('../../data/tidy/preprocessed_images/size64_exp5_PrPo_Im.npy', allow_pickle=True)\n",
    "images_size64_exp5_Pr_PoIm = np.load('../../data/tidy/preprocessed_images/size64_exp5_Pr_PoIm.npy', allow_pickle=True)\n",
    "\n",
    "images_size128_exp5_Pr_Po_Im = np.load('../../data/tidy/preprocessed_images/size128_exp5_Pr_Po_Im.npy', allow_pickle=True)\n",
    "images_size128_exp5_Pr_Im = np.load('../../data/tidy/preprocessed_images/size128_exp5_Pr_Im.npy', allow_pickle=True)\n",
    "images_size128_exp5_PrPo_Im = np.load('../../data/tidy/preprocessed_images/size128_exp5_PrPo_Im.npy', allow_pickle=True)\n",
    "images_size128_exp5_Pr_PoIm = np.load('../../data/tidy/preprocessed_images/size128_exp5_Pr_PoIm.npy', allow_pickle=True)\n",
    "\n",
    "images_size224_exp5_Pr_Po_Im = np.load('../../data/tidy/preprocessed_images/size224_exp5_Pr_Po_Im.npy', allow_pickle=True)\n",
    "images_size224_exp5_Pr_Im = np.load('../../data/tidy/preprocessed_images/size224_exp5_Pr_Im.npy', allow_pickle=True)\n",
    "images_size224_exp5_PrPo_Im = np.load('../../data/tidy/preprocessed_images/size224_exp5_PrPo_Im.npy', allow_pickle=True)\n",
    "images_size224_exp5_Pr_PoIm = np.load('../../data/tidy/preprocessed_images/size224_exp5_Pr_PoIm.npy', allow_pickle=True)\n",
    "\n",
    "images_size384_exp5_Pr_Po_Im = np.load('../../data/tidy/preprocessed_images/size384_exp5_Pr_Po_Im.npy', allow_pickle=True)\n",
    "images_size384_exp5_Pr_Im = np.load('../../data/tidy/preprocessed_images/size384_exp5_Pr_Im.npy', allow_pickle=True)\n",
    "images_size384_exp5_PrPo_Im = np.load('../../data/tidy/preprocessed_images/size384_exp5_PrPo_Im.npy', allow_pickle=True)\n",
    "images_size384_exp5_Pr_PoIm = np.load('../../data/tidy/preprocessed_images/size384_exp5_Pr_PoIm.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitData(image_array, prop = 0.80, seed_num = 111):\n",
    "    \"\"\"Returns training and test arrays of images with specified proportion - prop:1-prop\"\"\"\n",
    "    random.Random(seed_num).shuffle(image_array)\n",
    "    train_size = int(prop*np.shape(image_array)[0])\n",
    "    train = image_array[:train_size]\n",
    "    test = image_array[train_size:]\n",
    "    return(train, test)\n",
    "\n",
    "def getImageShape(image_array):\n",
    "    if NUM_CHANNEL==1:\n",
    "        image_shape = np.array([np.expand_dims(x[0],axis=2) for x in image_array]).shape[1:4]\n",
    "    elif NUM_CHANNEL==3:\n",
    "        image_shape = np.array([x[0] for x in image_array]).shape[1:4][::-1]\n",
    "    print(image_shape)\n",
    "    return image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n"
     ]
    }
   ],
   "source": [
    "class Histories(Callback):\n",
    "\n",
    "    def on_train_begin(self,logs={}):\n",
    "        self.losses = []\n",
    "        self.accuracies = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.accuracies.append(logs.get('acc'))\n",
    "\n",
    "\n",
    "histories = Histories()\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=1,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test),\n",
    "          callbacks=[histories]\n",
    "         )\n",
    "#Source: https://stackoverflow.com/a/52206330/3023033"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The resolution test will be conducted scenario by scenario.\n",
    "def test_resolution_performance(scenario):\n",
    "    if scenario == \"Pr_Po_Im\":\n",
    "        imageset = [images_size64_exp5_Pr_Po_Im, images_size128_exp5_Pr_Po_Im, images_size224_exp5_Pr_Po_Im, images_size384_exp5_Pr_Po_Im]\n",
    "    elif scenario == \"Pr_Im\":\n",
    "        imageset = [images_size64_exp5_Pr_Im, images_size128_exp5_Pr_Im, images_size224_exp5_Pr_Im, images_size384_exp5_Pr_Im]\n",
    "    elif scenario == \"PrPo_Im\":\n",
    "        imageset = [images_size64_exp5_PrPo_Im, images_size128_exp5_PrPo_Im, images_size224_exp5_PrPo_Im, images_size384_exp5_PrPo_Im]\n",
    "    elif scenario == \"Pr_PoIm\":\n",
    "        imageset = [images_size64_exp5_Pr_PoIm, images_size128_exp5_Pr_PoIm, images_size224_exp5_Pr_PoIm, images_size384_exp5_Pr_PoIm]\n",
    "\n",
    "    for resolution_set in imageset:\n",
    "        training_images, test_images = splitData(resolution_set, prop = 0.80, seed_num = 111)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "# Can either load a previously saved model or define here.\n",
    "# model = models.load_model('../../results/models/MODEL_NAME')\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(filters = 64, kernel_size = 7, strides = 2, activation=\"relu\", padding=\"same\", input_shape = input_image_shape),\n",
    "    layers.MaxPooling2D(2),\n",
    "    layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
    "    layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
    "    layers.MaxPooling2D(2),\n",
    "    layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n",
    "    layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n",
    "    layers.MaxPooling2D(2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation=\"relu\"),\n",
    "    layers.Dropout(0.5), # randomly drop out 50% of the neuorns at each training step\n",
    "    layers.Dense(64, activation=\"relu\"), # flatten all outputs\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(NUM_CLASS, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# Compile the model.\n",
    "opt = SGD(lr = 0.001) #default learning rate (lr) = 0.1\n",
    "model.compile(loss='categorical_crossentropy',  optimizer = \"adam\", metrics=[precision,recall, f1, 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_accuracy(hist):\n",
    "    plt.plot(hist.history[\"accuracy\"])\n",
    "    plt.plot(hist.history[\"val_accuracy\"])\n",
    "    plt.title(\"Model Accuracy\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.legend([\"Train\", \"Validation\"], loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_model_loss(hist):\n",
    "    plt.plot(hist.history[\"loss\"])\n",
    "    plt.plot(hist.history[\"val_loss\"])\n",
    "    plt.title(\"Model Loss\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.legend([\"Train\", \"Validation\"], loc=\"upper right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "hist_seq = model.fit(\n",
    "    train_array, train_labels, \n",
    "    batch_size = 32,\n",
    "    epochs = 5,\n",
    "    validation_data=(validation_array, validation_labels)\n",
    ")\n",
    "end = timer()\n",
    "print(end - start) # Time in seconds, e.g. 5.380919524002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_accuracy(hist_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_loss(hist_seq)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
