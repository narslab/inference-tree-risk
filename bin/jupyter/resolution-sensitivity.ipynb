{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script explores CNN model performance based on training image resolution.\n",
    "# We test the following training image sizes:\n",
    "# 64 x 64, 128 x 128, 224 x 224, 384 x 384\n",
    "\n",
    "import numpy as np\n",
    "from timeit import default_timer as timer\n",
    "import matplotlib.pyplot as plt\n",
    "import pydot\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "        \n",
    "from sklearn.metrics import recall_score, classification_report\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "import json\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../python/\")\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_size64_exp5_Pr_Po_Im = np.load('../../data/tidy/preprocessed_images/size64_exp5_Pr_Po_Im.npy', allow_pickle=True)\n",
    "images_size64_exp5_Pr_Im = np.load('../../data/tidy/preprocessed_images/size64_exp5_Pr_Im.npy', allow_pickle=True)\n",
    "images_size64_exp5_PrPo_Im = np.load('../../data/tidy/preprocessed_images/size64_exp5_PrPo_Im.npy', allow_pickle=True)\n",
    "images_size64_exp5_Pr_PoIm = np.load('../../data/tidy/preprocessed_images/size64_exp5_Pr_PoIm.npy', allow_pickle=True)\n",
    "\n",
    "images_size128_exp5_Pr_Po_Im = np.load('../../data/tidy/preprocessed_images/size128_exp5_Pr_Po_Im.npy', allow_pickle=True)\n",
    "images_size128_exp5_Pr_Im = np.load('../../data/tidy/preprocessed_images/size128_exp5_Pr_Im.npy', allow_pickle=True)\n",
    "images_size128_exp5_PrPo_Im = np.load('../../data/tidy/preprocessed_images/size128_exp5_PrPo_Im.npy', allow_pickle=True)\n",
    "images_size128_exp5_Pr_PoIm = np.load('../../data/tidy/preprocessed_images/size128_exp5_Pr_PoIm.npy', allow_pickle=True)\n",
    "\n",
    "images_size224_exp5_Pr_Po_Im = np.load('../../data/tidy/preprocessed_images/size224_exp5_Pr_Po_Im.npy', allow_pickle=True)\n",
    "images_size224_exp5_Pr_Im = np.load('../../data/tidy/preprocessed_images/size224_exp5_Pr_Im.npy', allow_pickle=True)\n",
    "images_size224_exp5_PrPo_Im = np.load('../../data/tidy/preprocessed_images/size224_exp5_PrPo_Im.npy', allow_pickle=True)\n",
    "images_size224_exp5_Pr_PoIm = np.load('../../data/tidy/preprocessed_images/size224_exp5_Pr_PoIm.npy', allow_pickle=True)\n",
    "\n",
    "images_size384_exp5_Pr_Po_Im = np.load('../../data/tidy/preprocessed_images/size384_exp5_Pr_Po_Im.npy', allow_pickle=True)\n",
    "images_size384_exp5_Pr_Im = np.load('../../data/tidy/preprocessed_images/size384_exp5_Pr_Im.npy', allow_pickle=True)\n",
    "images_size384_exp5_PrPo_Im = np.load('../../data/tidy/preprocessed_images/size384_exp5_PrPo_Im.npy', allow_pickle=True)\n",
    "images_size384_exp5_Pr_PoIm = np.load('../../data/tidy/preprocessed_images/size384_exp5_Pr_PoIm.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NUM_CLASS = 2\n",
    "NUM_CHANNELS = 1\n",
    "SCENARIO_LIST = [\"Pr_Po_Im\", \"Pr_Im\", \"PrPo_Im\", \"Pr_PoIm\"]\n",
    "RESOLUTION_PERFORMANCE_METRICS_DIR = '../../results/resolution-tests'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64, 1)\n",
      "(128, 128, 1)\n",
      "(224, 224, 1)\n",
      "(384, 384, 1)\n"
     ]
    }
   ],
   "source": [
    "input_image_shape_64 = getImageShape(images_size64_exp5_Pr_Im, num_channels = NUM_CHANNELS)\n",
    "input_image_shape_128 = getImageShape(images_size128_exp5_Pr_Im, num_channels = NUM_CHANNELS)\n",
    "input_image_shape_224 = getImageShape(images_size224_exp5_Pr_Im, num_channels = NUM_CHANNELS)\n",
    "input_image_shape_384 = getImageShape(images_size384_exp5_Pr_Im, num_channels = NUM_CHANNELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOptCNNParams(image_size):\n",
    "    opt_params = dict.fromkeys(SCENARIO_LIST)\n",
    "    for s in SCENARIO_LIST:\n",
    "        with open('../../results/models/' + str(image_size) + '/' + s + '/attributes/hyperparameters.txt') as f: \n",
    "            data = f.read() \n",
    "        js = json.loads(data)   \n",
    "        opt_params[s] = js\n",
    "    return(opt_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_params_64 = getOptCNNParams(64)\n",
    "opt_params_128 = getOptCNNParams(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can either load a previously saved model or define here.\n",
    "# model = models.load_model('../../results/models/MODEL_NAME')\n",
    "def constructBaseCNN(image_shape, scenario, opt_params_dict):\n",
    "    p_dict = opt_params_dict[scenario]\n",
    "    if scenario==\"Pr_Po_Im\":\n",
    "        num_classes = 3\n",
    "    else:\n",
    "        num_classes = 2\n",
    "    base_model = models.Sequential([\n",
    "        layers.Conv2D(filters = 64, kernel_size = p_dict['kernel_size'], strides = 2, activation=\"relu\", padding=\"same\", input_shape = image_shape),\n",
    "        layers.MaxPooling2D(2),\n",
    "        layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
    "        layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
    "        layers.MaxPooling2D(2),\n",
    "        layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n",
    "        layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n",
    "        layers.MaxPooling2D(2),\n",
    "        layers.Flatten(),\n",
    "        \n",
    "        layers.Dense(p_dict['units'], activation = p_dict['activation']),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(p_dict['dropout']), \n",
    "        \n",
    "        layers.Dense(p_dict['units'], activation = p_dict['activation']), \n",
    "        layers.Dropout(p_dict['dropout']),\n",
    "        \n",
    "        layers.Dense(num_classes, activation=\"softmax\")\n",
    "    ])\n",
    "    learning_rate = p_dict['learning_rate']\n",
    "    return(base_model, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The resolution test will be conducted scenario by scenario.\n",
    "def testResolutionPerformance(scenario, opt_params = opt_params_64, num_epochs = 10, trial_seed = 1): \n",
    "    resolution_keys = [64, 128, 224, 384]\n",
    "    performance_dict = dict.fromkeys(resolution_keys)\n",
    "    if scenario == \"Pr_Po_Im\":\n",
    "        imageset = [images_size64_exp5_Pr_Po_Im, images_size128_exp5_Pr_Po_Im, images_size224_exp5_Pr_Po_Im, images_size384_exp5_Pr_Po_Im]\n",
    "    elif scenario == \"Pr_Im\":\n",
    "        imageset = [images_size64_exp5_Pr_Im]#, images_size128_exp5_Pr_Im, images_size224_exp5_Pr_Im, images_size384_exp5_Pr_Im]\n",
    "    elif scenario == \"PrPo_Im\":\n",
    "        imageset = [images_size64_exp5_PrPo_Im, images_size128_exp5_PrPo_Im, images_size224_exp5_PrPo_Im, images_size384_exp5_PrPo_Im]\n",
    "    elif scenario == \"Pr_PoIm\":\n",
    "        imageset = [images_size64_exp5_Pr_PoIm, images_size128_exp5_Pr_PoIm, images_size224_exp5_Pr_PoIm, images_size384_exp5_Pr_PoIm]\n",
    "\n",
    "    k = 0\n",
    "    for resolution_set in imageset:\n",
    "        res_key = resolution_keys[k]\n",
    "        performance_dict[res_key] = {}\n",
    "        training_images_and_labels, test_images_and_labels = splitData(resolution_set, prop = 0.80, seed_num = trial_seed)\n",
    "        training_images, training_labels = getImageAndLabelArrays(training_images_and_labels)\n",
    "        validation_images, validation_labels = getImageAndLabelArrays(test_images_and_labels)\n",
    "        # early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "        # batch_training_histories = Histories()\n",
    "        # metrics_multiclass = Metrics(validation_images,validation_labels)  TODO\n",
    "        # K.clear_session()\n",
    "        input_shape = (res_key, res_key, NUM_CHANNELS)\n",
    "        model, opt_learning_rate =  constructBaseCNN(input_shape, scenario, opt_params)\n",
    "        reset_weights(model) # re-initialize model weights\n",
    "        opt = tf.keras.optimizers.Adam(learning_rate = opt_learning_rate)\n",
    "        model.compile(loss='categorical_crossentropy',  optimizer = \"adam\", metrics = ['accuracy'])\n",
    "        hist = model.fit(training_images, training_labels, batch_size = 32, epochs = num_epochs, verbose=0, validation_data=(validation_images, validation_labels)) #, callbacks=[batch_training_histories])\n",
    "        performance_dict[res_key]['scenario'] = scenario\n",
    "        performance_dict[res_key]['image_size'] = res_key\n",
    "        performance_dict[res_key]['metrics'] = hist\n",
    "        performance_dict[res_key]['best_val_acc'] = np.max(hist.history['val_accuracy'])\n",
    "        k += 1    \n",
    "    return(performance_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(num_trials = 5):\n",
    "    scenario_performance_dict = dict.fromkeys(SCENARIO_LIST)\n",
    "    if not os.path.exists(RESOLUTION_PERFORMANCE_METRICS_DIR): # check if 'tidy/preprocessed_images' subdirectory does not exist\n",
    "        os.makedirs(RESOLUTION_PERFORMANCE_METRICS_DIR) # if not, create it    \n",
    "    for i in range(num_trials):\n",
    "        for s in SCENARIO_LIST:\n",
    "            print(\"Conducting resolution performance test; Scenario: \" + s + \"; Trial: \" + str(i+1))\n",
    "            scenario_performance_dict[s] = testResolutionPerformance(s, opt_params = opt_params_64, num_epochs = 10, trial_seed = 1 + i) #ultimately should be averaged across trials       \n",
    "            scenario_filename = \"resolution_performance_\" + s + \"_trial_\" + str(i+1) + \".txt\"\n",
    "            with open(os.path.join(RESOLUTION_PERFORMANCE_METRICS_DIR, scenario_filename), 'w') as file:\n",
    "                file.write(json.dump(scenario_performance_dict)) # use `json.loads` to do the reverse\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conducting resolution performance test; Scenario: Pr_Po_Im; Trial: 1\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting \n",
    "# p1[64]['metrics'].history['loss']\n",
    "# plt.close('all')\n",
    "# for m in ['recall', 'precision', 'f1-score']:\n",
    "#     for c in [0,1,2]:\n",
    "#         plt.plot(metrics_multiclass.get(m,c), label='Class {0} {1}'.format(c,m))\n",
    "        \n",
    "# plt.legend(loc='lower right')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max([1,2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
