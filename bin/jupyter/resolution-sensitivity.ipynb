{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script explores CNN model performance based on training image resolution.\n",
    "# We test the following training image sizes:\n",
    "# 64 x 64, 128 x 128, 224 x 224, 384 x 384\n",
    "\n",
    "import numpy as np\n",
    "from timeit import default_timer as timer\n",
    "import matplotlib.pyplot as plt\n",
    "import pydot\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "        \n",
    "from sklearn.metrics import recall_score, classification_report\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "import json\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../python/\")\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NUM_CLASS = 2\n",
    "NUM_CHANNELS = 1\n",
    "RESOLUTION_LIST = [64, 128, 224, 384]\n",
    "SCENARIO_LIST = [\"Pr_Im\", \"PrPo_Im\", \"Pr_PoIm\", \"Pr_Po_Im\"]\n",
    "\n",
    "NUM_CHANNELS = 1\n",
    "SCENARIO_LIST = [\"Pr_Po_Im\", \"Pr_Im\", \"PrPo_Im\", \"Pr_PoIm\"]\n",
    "RESOLUTION_PERFORMANCE_METRICS_DIR = '../../results/resolution-tests'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createResolutionScenarioImageDict(resolution_list, scenario_list):\n",
    "    image_dict = dict.fromkeys(resolution_list)\n",
    "    for p in resolution_list:\n",
    "        image_dict[p] = dict.fromkeys(scenario_list)\n",
    "        for s in scenario_list:\n",
    "            image_dict[p][s] = np.load('../../data/tidy/preprocessed_images/size' + str(p) + '_exp5_' + s + '.npy', allow_pickle = True)\n",
    "    return(image_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64, 1)\n",
      "(128, 128, 1)\n",
      "(224, 224, 1)\n",
      "(384, 384, 1)\n"
     ]
    }
   ],
   "source": [
    "image_sets = createResolutionScenarioImageDict(RESOLUTION_LIST, SCENARIO_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOptCNNHyperparams(image_size, scenario):\n",
    "    #opt_params = dict.fromkeys(SCENARIO_LIST)\n",
    "    #for s in SCENARIO_LIST:\n",
    "    with open('../../results/models/' + str(image_size) + '/' + s + '/hyperparameters.txt') as f: \n",
    "        data = f.read() \n",
    "    opt_params_dict = json.loads(data)   \n",
    "        #opt_params[s] = js\n",
    "    return(opt_params_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constructBaseCNN(image_size, scenario):\n",
    "    image_shape = (image_size, imag_size, NUM_CHANNELS)\n",
    "    p_dict = getOptCNNHyperparams(image_size, scenario)\n",
    "    if scenario==\"Pr_Po_Im\":\n",
    "        num_classes = 3\n",
    "    else:\n",
    "        num_classes = 2\n",
    "    base_model = models.Sequential([\n",
    "        layers.Conv2D(filters = 64, kernel_size = p_dict['kernel_size'], strides = 2, activation=\"relu\", padding=\"same\", input_shape = image_shape),\n",
    "        layers.MaxPooling2D(2),\n",
    "        layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
    "        layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
    "        layers.MaxPooling2D(2),\n",
    "        layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n",
    "        layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n",
    "        layers.MaxPooling2D(2),\n",
    "        layers.Flatten(),\n",
    "        \n",
    "        layers.Dense(p_dict['units_1'], activation = p_dict['activation_1']),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(p_dict['dropout_1']), \n",
    "        \n",
    "        layers.Dense(p_dict['units_2'], activation = p_dict['activation_2']), \n",
    "        layers.Dropout(p_dict['dropout_2']),\n",
    "        \n",
    "        layers.Dense(num_classes, activation=\"softmax\")\n",
    "    ])\n",
    "    learning_rate = p_dict['learning_rate']\n",
    "    return(base_model, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The resolution test will be conducted scenario by scenario.\n",
    "def testResolutionPerformance(image_size, scenario, num_epochs = 10, trial_seed = 1):  # opt_params = opt_params_64, \n",
    "    performance_dict = {}\n",
    "    training_images_and_labels, test_images_and_labels = splitData(resolution_set, prop = 0.80, seed_num = trial_seed)\n",
    "    training_images, training_labels = getImageAndLabelArrays(training_images_and_labels)\n",
    "    validation_images, validation_labels = getImageAndLabelArrays(test_images_and_labels)\n",
    "    # early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "    # batch_training_histories = Histories()\n",
    "    # metrics_multiclass = Metrics(validation_images,validation_labels)  TODO\n",
    "    # K.clear_session()\n",
    "    input_shape = (res_key, res_key, NUM_CHANNELS)\n",
    "    model =  constructBaseCNN(image_size, scenario)\n",
    "    opt_learning_rate = getOptCNNHyperparams(image_size, scenario)['learning_rate']\n",
    "    reset_weights(model) # re-initialize model weights\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate = opt_learning_rate)\n",
    "    model.compile(loss='categorical_crossentropy',  optimizer = \"adam\", metrics = ['accuracy'])\n",
    "    hist = model.fit(training_images, training_labels, batch_size = 32, epochs = num_epochs, verbose=0, validation_data=(validation_images, validation_labels)) #, callbacks=[batch_training_histories])\n",
    "    performance_dict['scenario'] = scenario\n",
    "    performance_dict['image_size'] = res_key\n",
    "    performance_dict['metrics'] = hist\n",
    "    performance_dict['best_val_accuracy'] = np.max(hist.history['val_accuracy'])\n",
    "    return(performance_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testScenarioPerformance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(num_trials = 5):\n",
    "    scenario_performance_dict = dict.fromkeys(SCENARIO_LIST)\n",
    "    if not os.path.exists(RESOLUTION_PERFORMANCE_METRICS_DIR): # check if 'tidy/preprocessed_images' subdirectory does not exist\n",
    "        os.makedirs(RESOLUTION_PERFORMANCE_METRICS_DIR) # if not, create it    \n",
    "    for i in range(num_trials):\n",
    "        for s in SCENARIO_LIST:\n",
    "            print(\"Conducting resolution performance test; Scenario: \" + s + \"; Trial: \" + str(i+1))\n",
    "            scenario_performance_dict[s] = testResolutionPerformance(s, opt_params = opt_params_64, num_epochs = 10, trial_seed = 1 + i) #ultimately should be averaged across trials       \n",
    "            scenario_filename = \"resolution_performance_\" + s + \"_trial_\" + str(i+1) + \".txt\"\n",
    "            #with open(os.path.join(RESOLUTION_PERFORMANCE_METRICS_DIR, scenario_filename), 'w') as file:\n",
    "            pickle.dump(scenario_performance_dict, open(os.path.join(RESOLUTION_PERFORMANCE_METRICS_DIR, scenario_filename), 'w')) # use `json.loads` to do the reverse\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conducting resolution performance test; Scenario: Pr_Po_Im; Trial: 1\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "dump() missing 1 required positional argument: 'fp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-972361fa1b80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-70-2a23f87f103c>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(num_trials)\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mscenario_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"resolution_performance_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_trial_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".txt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRESOLUTION_PERFORMANCE_METRICS_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscenario_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                 \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscenario_performance_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# use `json.loads` to do the reverse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: dump() missing 1 required positional argument: 'fp'"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting \n",
    "# p1[64]['metrics'].history['loss']\n",
    "# plt.close('all')\n",
    "# for m in ['recall', 'precision', 'f1-score']:\n",
    "#     for c in [0,1,2]:\n",
    "#         plt.plot(metrics_multiclass.get(m,c), label='Class {0} {1}'.format(c,m))\n",
    "        \n",
    "# plt.legend(loc='lower right')\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
