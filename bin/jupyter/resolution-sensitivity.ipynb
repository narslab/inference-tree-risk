{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script explores CNN model performance based on training image resolution.\n",
    "# We test the following training image sizes:\n",
    "# 64 x 64, 128 x 128, 224 x 224, 384 x 384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from timeit import default_timer as timer\n",
    "import matplotlib.pyplot as plt\n",
    "import pydot\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "        \n",
    "from sklearn.metrics import recall_score, classification_report\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_size64_exp5_Pr_Po_Im = np.load('../../data/tidy/preprocessed_images/size64_exp5_Pr_Po_Im.npy', allow_pickle=True)\n",
    "images_size64_exp5_Pr_Im = np.load('../../data/tidy/preprocessed_images/size64_exp5_Pr_Im.npy', allow_pickle=True)\n",
    "images_size64_exp5_PrPo_Im = np.load('../../data/tidy/preprocessed_images/size64_exp5_PrPo_Im.npy', allow_pickle=True)\n",
    "images_size64_exp5_Pr_PoIm = np.load('../../data/tidy/preprocessed_images/size64_exp5_Pr_PoIm.npy', allow_pickle=True)\n",
    "\n",
    "images_size128_exp5_Pr_Po_Im = np.load('../../data/tidy/preprocessed_images/size128_exp5_Pr_Po_Im.npy', allow_pickle=True)\n",
    "images_size128_exp5_Pr_Im = np.load('../../data/tidy/preprocessed_images/size128_exp5_Pr_Im.npy', allow_pickle=True)\n",
    "images_size128_exp5_PrPo_Im = np.load('../../data/tidy/preprocessed_images/size128_exp5_PrPo_Im.npy', allow_pickle=True)\n",
    "images_size128_exp5_Pr_PoIm = np.load('../../data/tidy/preprocessed_images/size128_exp5_Pr_PoIm.npy', allow_pickle=True)\n",
    "\n",
    "images_size224_exp5_Pr_Po_Im = np.load('../../data/tidy/preprocessed_images/size224_exp5_Pr_Po_Im.npy', allow_pickle=True)\n",
    "images_size224_exp5_Pr_Im = np.load('../../data/tidy/preprocessed_images/size224_exp5_Pr_Im.npy', allow_pickle=True)\n",
    "images_size224_exp5_PrPo_Im = np.load('../../data/tidy/preprocessed_images/size224_exp5_PrPo_Im.npy', allow_pickle=True)\n",
    "images_size224_exp5_Pr_PoIm = np.load('../../data/tidy/preprocessed_images/size224_exp5_Pr_PoIm.npy', allow_pickle=True)\n",
    "\n",
    "images_size384_exp5_Pr_Po_Im = np.load('../../data/tidy/preprocessed_images/size384_exp5_Pr_Po_Im.npy', allow_pickle=True)\n",
    "images_size384_exp5_Pr_Im = np.load('../../data/tidy/preprocessed_images/size384_exp5_Pr_Im.npy', allow_pickle=True)\n",
    "images_size384_exp5_PrPo_Im = np.load('../../data/tidy/preprocessed_images/size384_exp5_PrPo_Im.npy', allow_pickle=True)\n",
    "images_size384_exp5_Pr_PoIm = np.load('../../data/tidy/preprocessed_images/size384_exp5_Pr_PoIm.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASS = 2\n",
    "NUM_CHANNEL = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitData(image_array, prop = 0.80, seed_num = 111):\n",
    "    \"\"\"Returns training and test arrays of images with specified proportion - prop:1-prop\"\"\"\n",
    "    random.Random(seed_num).shuffle(image_array)\n",
    "    train_size = int(prop*np.shape(image_array)[0])\n",
    "    train = image_array[:train_size]\n",
    "    test = image_array[train_size:]\n",
    "    return(train, test)\n",
    "\n",
    "def getImageShape(image_array):\n",
    "    \"\"\"Returns shape of image from array of images, e.g. WIDTH x HEIGHT x NUM_CHANNELS\"\"\"\n",
    "    if NUM_CHANNEL==1:\n",
    "        image_shape = np.array([np.expand_dims(x[0],axis=2) for x in image_array]).shape[1:4]\n",
    "    elif NUM_CHANNEL==3:\n",
    "        image_shape = np.array([x[0] for x in image_array]).shape[1:4][::-1]\n",
    "    print(image_shape)\n",
    "    return image_shape\n",
    "\n",
    "def getImageAndLabelArrays(image_label_tuple_array, num_channels = 1):\n",
    "    \"\"\"Separates array of tuples (image matrix, vector label) into array of image matrices and array of image labels\"\"\"\n",
    "    if num_channels == 1:\n",
    "        image_array = np.array([np.expand_dims(x[0],axis=2) for x in image_label_tuple_array])\n",
    "    elif num_channels == 3:\n",
    "        image_array = np.array([x[0] for x in image_label_tuple_array]) \n",
    "        image_array = np.moveaxis(image_array, 1, -1)\n",
    "    label_array = np.array([x[1] for x in image_label_tuple_array])\n",
    "    return(image_array, label_array)\n",
    "\n",
    "#https://github.com/keras-team/keras/issues/5400#issuecomment-408743570\n",
    "def check_units(y_true, y_pred):\n",
    "    if y_pred.shape[1] != 1:\n",
    "      y_pred = y_pred[:,1:2]\n",
    "      y_true = y_true[:,1:2]\n",
    "    return y_true, y_pred\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    y_true, y_pred = check_units(y_true, y_pred)\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    y_true, y_pred = check_units(y_true, y_pred)\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    y_true, y_pred = check_units(y_true, y_pred)\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "   \n",
    "def reset_weights(model):\n",
    "    \"\"\"This function re-initializes model weights at each compile\"\"\"\n",
    "    for layer in model.layers: \n",
    "        if isinstance(layer, tf.keras.Model):\n",
    "            reset_weights(layer)\n",
    "            continue\n",
    "    for k, initializer in layer.__dict__.items():\n",
    "        if \"initializer\" not in k:\n",
    "            continue\n",
    "        # find the corresponding variable\n",
    "        var = getattr(layer, k.replace(\"_initializer\", \"\"))\n",
    "        var.assign(initializer(var.shape, var.dtype))\n",
    "\n",
    "# define callback to save batch-wise loss/accuracy; Source: https://stackoverflow.com/a/52206330/3023033\n",
    "class Histories(Callback):\n",
    "    def on_train_begin(self,logs={}):\n",
    "        self.losses = []\n",
    "        self.accuracies = []\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.accuracies.append(logs.get('accuracy'))\n",
    "\n",
    "# Callback to find metrics at epoch end (not perfectly implemented; TODO) # Source: https://stackoverflow.com/a/56485026/3023033\n",
    "class Metrics(Callback):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y if (y.ndim == 1 or y.shape[1] == 1) else np.argmax(y, axis=1)\n",
    "        self.reports = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_hat = np.asarray(self.model.predict(self.x))\n",
    "        y_hat = np.where(y_hat > 0.5, 1, 0) if (y_hat.ndim == 1 or y_hat.shape[1] == 1)  else np.argmax(y_hat, axis=1)\n",
    "        report = classification_report(self.y,y_hat,output_dict=True)\n",
    "        self.reports.append(report)\n",
    "        return\n",
    "   \n",
    "    # Utility method\n",
    "    def get(self, metrics, of_class):\n",
    "        return [report[str(of_class)][metrics] for report in self.reports]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64, 1)\n",
      "(128, 128, 1)\n",
      "(224, 224, 1)\n",
      "(384, 384, 1)\n"
     ]
    }
   ],
   "source": [
    "input_image_shape_64 = getImageShape(images_size64_exp5_Pr_Im)\n",
    "input_image_shape_128 = getImageShape(images_size128_exp5_Pr_Im)\n",
    "input_image_shape_224 = getImageShape(images_size224_exp5_Pr_Im)\n",
    "input_image_shape_384 = getImageShape(images_size384_exp5_Pr_Im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can either load a previously saved model or define here.\n",
    "# model = models.load_model('../../results/models/MODEL_NAME')\n",
    "base_model_64 = models.Sequential([\n",
    "    layers.Conv2D(filters = 64, kernel_size = 7, strides = 2, activation=\"relu\", padding=\"same\", input_shape = input_image_shape_64),\n",
    "    layers.MaxPooling2D(2),\n",
    "    layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
    "    layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
    "    layers.MaxPooling2D(2),\n",
    "    layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n",
    "    layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n",
    "    layers.MaxPooling2D(2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation=\"relu\"),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.5), # randomly drop out 50% of the neuorns at each training step\n",
    "    layers.Dense(64, activation=\"relu\"), # flatten all outputs\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(NUM_CLASS, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "base_model_128 = models.Sequential([\n",
    "    layers.Conv2D(filters = 64, kernel_size = 7, strides = 2, activation=\"relu\", padding=\"same\", input_shape = input_image_shape_128),\n",
    "    layers.MaxPooling2D(2),\n",
    "    layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
    "    layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
    "    layers.MaxPooling2D(2),\n",
    "    layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n",
    "    layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n",
    "    layers.MaxPooling2D(2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation=\"relu\"),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.5), # randomly drop out 50% of the neuorns at each training step\n",
    "    layers.Dense(64, activation=\"relu\"), # flatten all outputs\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(NUM_CLASS, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "base_model_224 = models.Sequential([\n",
    "    layers.Conv2D(filters = 64, kernel_size = 7, strides = 2, activation=\"relu\", padding=\"same\", input_shape = input_image_shape_224),\n",
    "    layers.MaxPooling2D(2),\n",
    "    layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
    "    layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
    "    layers.MaxPooling2D(2),\n",
    "    layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n",
    "    layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n",
    "    layers.MaxPooling2D(2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation=\"relu\"),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.5), # randomly drop out 50% of the neuorns at each training step\n",
    "    layers.Dense(64, activation=\"relu\"), # flatten all outputs\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(NUM_CLASS, activation=\"softmax\")\n",
    "])\n",
    "base_model_384 = models.Sequential([\n",
    "    layers.Conv2D(filters = 64, kernel_size = 7, strides = 2, activation=\"relu\", padding=\"same\", input_shape = input_image_shape_384),\n",
    "    layers.MaxPooling2D(2),\n",
    "    layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
    "    layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
    "    layers.MaxPooling2D(2),\n",
    "    layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n",
    "    layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n",
    "    layers.MaxPooling2D(2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation=\"relu\"),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.5), # randomly drop out 50% of the neuorns at each training step\n",
    "    layers.Dense(64, activation=\"relu\"), # flatten all outputs\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(NUM_CLASS, activation=\"softmax\")\n",
    "])\n",
    "# Compile the model.\n",
    "#opt = SGD(lr = 0.001) #default learning rate (lr) = 0.1\n",
    "# opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "#model.compile(loss='categorical_crossentropy',  optimizer = \"adam\", metrics=[precision,recall, f1, 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The resolution test will be conducted scenario by scenario.\n",
    "def test_resolution_performance(scenario, model_list, num_epochs = 10, trial_seed = 1): \n",
    "    resolution_keys = [64, 128, 224, 384]\n",
    "    performance_dict = dict.fromkeys(resolution_keys)\n",
    "    if scenario == \"Pr_Po_Im\":\n",
    "        imageset = [images_size64_exp5_Pr_Po_Im, images_size128_exp5_Pr_Po_Im, images_size224_exp5_Pr_Po_Im, images_size384_exp5_Pr_Po_Im]\n",
    "    elif scenario == \"Pr_Im\":\n",
    "        imageset = [images_size64_exp5_Pr_Im]#, images_size128_exp5_Pr_Im, images_size224_exp5_Pr_Im, images_size384_exp5_Pr_Im]\n",
    "    elif scenario == \"PrPo_Im\":\n",
    "        imageset = [images_size64_exp5_PrPo_Im, images_size128_exp5_PrPo_Im, images_size224_exp5_PrPo_Im, images_size384_exp5_PrPo_Im]\n",
    "    elif scenario == \"Pr_PoIm\":\n",
    "        imageset = [images_size64_exp5_Pr_PoIm, images_size128_exp5_Pr_PoIm, images_size224_exp5_Pr_PoIm, images_size384_exp5_Pr_PoIm]\n",
    "\n",
    "    k = 0\n",
    "    for resolution_set in imageset:\n",
    "        res_key = resolution_keys[k]\n",
    "        performance_dict[res_key] = {}\n",
    "        \n",
    "        training_images_and_labels, test_images_and_labels = splitData(resolution_set, prop = 0.80, seed_num = trial_seed)\n",
    "        training_images, training_labels = getImageAndLabelArrays(training_images_and_labels)\n",
    "        validation_images, validation_labels = getImageAndLabelArrays(test_images_and_labels)\n",
    "        batch_training_histories = Histories()\n",
    "        # metrics_multiclass = Metrics(validation_images,validation_labels)  TODO\n",
    "        # K.clear_session()\n",
    "        model = model_list[k] # select k'th model from list\n",
    "        reset_weights(model) # re-initialize model weights\n",
    "        model.compile(loss='categorical_crossentropy',  optimizer = \"adam\", metrics = ['accuracy'])\n",
    "        hist = model.fit(training_images, training_labels, batch_size = 32, epochs = num_epochs, verbose=1, validation_data=(validation_images, validation_labels)) #, callbacks=[batch_training_histories])\n",
    "        performance_dict[res_key]['scenario'] = scenario\n",
    "        performance_dict[res_key]['image_size'] = res_key\n",
    "        performance_dict[res_key]['metrics'] = hist\n",
    "        k += 1    \n",
    "    return(performance_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESOLUTION_PERFORMANCE_METRICS_DIR = '../../results/resolution-tests'\n",
    "def main(num_trials = 5):\n",
    "    scenario_list = [\"Pr_Po_Im\", \"Pr_Im\", \"PrPo_Im\", \"Pr_PoIm\"]\n",
    "    optimized_models = [base_model_64, base_model_128, base_model_224, base_model_384] # TO BE UPDATED\n",
    "    scenario_performance_dict = dict.fromkeys(scenario_list)\n",
    "    if not os.path.exists(RESOLUTION_PERFORMANCE_METRICS_DIR): # check if 'tidy/preprocessed_images' subdirectory does not exist\n",
    "        os.makedirs(RESOLUTION_PERFORMANCE_METRICS_DIR) # if not, create it    \n",
    "    for i in range(num_trials):\n",
    "        for j in scenario_list:\n",
    "            scenario_performance_dict[j] = test_resolution_performance(j, optimized_models, num_epochs = 10, trial_seed = 1 + i) #ultimately should be averaged across trials       \n",
    "        scenario_filename = \"resolution_performance_\" + j + \"_trial_\" + str(i) + \".txt\"\n",
    "        with open(os.path.join(RESOLUTION_PERFORMANCE_METRICS_DIR, data_filename), 'w') as file:\n",
    "            file.write(json.dumps(scenario_performance_dict)) # use `json.loads` to do the reverse\n",
    "    return()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting \n",
    "# p1[64]['metrics'].history['loss']\n",
    "# plt.close('all')\n",
    "# for m in ['recall', 'precision', 'f1-score']:\n",
    "#     for c in [0,1,2]:\n",
    "#         plt.plot(metrics_multiclass.get(m,c), label='Class {0} {1}'.format(c,m))\n",
    "        \n",
    "# plt.legend(loc='lower right')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_accuracy(hist):\n",
    "    plt.plot(hist.history[\"accuracy\"])\n",
    "    plt.plot(hist.history[\"val_accuracy\"])\n",
    "    plt.title(\"Model Accuracy\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.legend([\"Train\", \"Validation\"], loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_model_batch_accuracy(hist):\n",
    "    #plt.plot(hist.accuracies)\n",
    "    plt.plot(hist.val_accuracies)\n",
    "    plt.title(\"Model Accuracy\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    #plt.legend([\"Train\", \"Validation\"], loc=\"lower right\")\n",
    "    plt.show()\n",
    "    \n",
    "def plot_model_loss(hist):\n",
    "    plt.plot(hist.history[\"loss\"])\n",
    "    plt.plot(hist.history[\"val_loss\"])\n",
    "    plt.title(\"Model Loss\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.legend([\"Train\", \"Validation\"], loc=\"upper right\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
