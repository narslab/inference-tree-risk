{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script explores CNN model performance based on training image resolution.\n",
    "# We test the following training image sizes:\n",
    "# 64 x 64, 128 x 128, 224 x 224, 384 x 384\n",
    "\n",
    "import numpy as np\n",
    "from timeit import default_timer as timer\n",
    "import matplotlib.pyplot as plt\n",
    "import pydot\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "        \n",
    "from sklearn.metrics import recall_score, classification_report\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "import json\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../python/\")\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_size64_exp5_Pr_Po_Im = np.load('../../data/tidy/preprocessed_images/size64_exp5_Pr_Po_Im.npy', allow_pickle=True)\n",
    "images_size64_exp5_Pr_Im = np.load('../../data/tidy/preprocessed_images/size64_exp5_Pr_Im.npy', allow_pickle=True)\n",
    "images_size64_exp5_PrPo_Im = np.load('../../data/tidy/preprocessed_images/size64_exp5_PrPo_Im.npy', allow_pickle=True)\n",
    "images_size64_exp5_Pr_PoIm = np.load('../../data/tidy/preprocessed_images/size64_exp5_Pr_PoIm.npy', allow_pickle=True)\n",
    "\n",
    "images_size128_exp5_Pr_Po_Im = np.load('../../data/tidy/preprocessed_images/size128_exp5_Pr_Po_Im.npy', allow_pickle=True)\n",
    "images_size128_exp5_Pr_Im = np.load('../../data/tidy/preprocessed_images/size128_exp5_Pr_Im.npy', allow_pickle=True)\n",
    "images_size128_exp5_PrPo_Im = np.load('../../data/tidy/preprocessed_images/size128_exp5_PrPo_Im.npy', allow_pickle=True)\n",
    "images_size128_exp5_Pr_PoIm = np.load('../../data/tidy/preprocessed_images/size128_exp5_Pr_PoIm.npy', allow_pickle=True)\n",
    "\n",
    "images_size224_exp5_Pr_Po_Im = np.load('../../data/tidy/preprocessed_images/size224_exp5_Pr_Po_Im.npy', allow_pickle=True)\n",
    "images_size224_exp5_Pr_Im = np.load('../../data/tidy/preprocessed_images/size224_exp5_Pr_Im.npy', allow_pickle=True)\n",
    "images_size224_exp5_PrPo_Im = np.load('../../data/tidy/preprocessed_images/size224_exp5_PrPo_Im.npy', allow_pickle=True)\n",
    "images_size224_exp5_Pr_PoIm = np.load('../../data/tidy/preprocessed_images/size224_exp5_Pr_PoIm.npy', allow_pickle=True)\n",
    "\n",
    "images_size384_exp5_Pr_Po_Im = np.load('../../data/tidy/preprocessed_images/size384_exp5_Pr_Po_Im.npy', allow_pickle=True)\n",
    "images_size384_exp5_Pr_Im = np.load('../../data/tidy/preprocessed_images/size384_exp5_Pr_Im.npy', allow_pickle=True)\n",
    "images_size384_exp5_PrPo_Im = np.load('../../data/tidy/preprocessed_images/size384_exp5_PrPo_Im.npy', allow_pickle=True)\n",
    "images_size384_exp5_Pr_PoIm = np.load('../../data/tidy/preprocessed_images/size384_exp5_Pr_PoIm.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASS = 2\n",
    "NUM_CHANNELS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image_shape_64 = getImageShape(images_size64_exp5_Pr_Im, num_channels = NUM_CHANNELS)\n",
    "input_image_shape_128 = getImageShape(images_size128_exp5_Pr_Im, num_channels = NUM_CHANNELS)\n",
    "input_image_shape_224 = getImageShape(images_size224_exp5_Pr_Im, num_channels = NUM_CHANNELS)\n",
    "input_image_shape_384 = getImageShape(images_size384_exp5_Pr_Im, num_channels = NUM_CHANNELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can either load a previously saved model or define here.\n",
    "# model = models.load_model('../../results/models/MODEL_NAME')\n",
    "base_model_64 = models.Sequential([\n",
    "    layers.Conv2D(filters = 64, kernel_size = 7, strides = 2, activation=\"relu\", padding=\"same\", input_shape = input_image_shape_64),\n",
    "    layers.MaxPooling2D(2),\n",
    "    layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
    "    layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
    "    layers.MaxPooling2D(2),\n",
    "    layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n",
    "    layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n",
    "    layers.MaxPooling2D(2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation=\"relu\"),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.5), # randomly drop out 50% of the neuorns at each training step\n",
    "    layers.Dense(64, activation=\"relu\"), # flatten all outputs\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(NUM_CLASS, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "base_model_128 = models.Sequential([\n",
    "    layers.Conv2D(filters = 64, kernel_size = 7, strides = 2, activation=\"relu\", padding=\"same\", input_shape = input_image_shape_128),\n",
    "    layers.MaxPooling2D(2),\n",
    "    layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
    "    layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
    "    layers.MaxPooling2D(2),\n",
    "    layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n",
    "    layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n",
    "    layers.MaxPooling2D(2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation=\"relu\"),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.5), # randomly drop out 50% of the neuorns at each training step\n",
    "    layers.Dense(64, activation=\"relu\"), # flatten all outputs\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(NUM_CLASS, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "base_model_224 = models.Sequential([\n",
    "    layers.Conv2D(filters = 64, kernel_size = 7, strides = 2, activation=\"relu\", padding=\"same\", input_shape = input_image_shape_224),\n",
    "    layers.MaxPooling2D(2),\n",
    "    layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
    "    layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
    "    layers.MaxPooling2D(2),\n",
    "    layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n",
    "    layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n",
    "    layers.MaxPooling2D(2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation=\"relu\"),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.5), # randomly drop out 50% of the neuorns at each training step\n",
    "    layers.Dense(64, activation=\"relu\"), # flatten all outputs\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(NUM_CLASS, activation=\"softmax\")\n",
    "])\n",
    "base_model_384 = models.Sequential([\n",
    "    layers.Conv2D(filters = 64, kernel_size = 7, strides = 2, activation=\"relu\", padding=\"same\", input_shape = input_image_shape_384),\n",
    "    layers.MaxPooling2D(2),\n",
    "    layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
    "    layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
    "    layers.MaxPooling2D(2),\n",
    "    layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n",
    "    layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n",
    "    layers.MaxPooling2D(2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation=\"relu\"),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.5), # randomly drop out 50% of the neuorns at each training step\n",
    "    layers.Dense(64, activation=\"relu\"), # flatten all outputs\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(NUM_CLASS, activation=\"softmax\")\n",
    "])\n",
    "# Compile the model.\n",
    "#opt = SGD(lr = 0.001) #default learning rate (lr) = 0.1\n",
    "# opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "#model.compile(loss='categorical_crossentropy',  optimizer = \"adam\", metrics=[precision,recall, f1, 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The resolution test will be conducted scenario by scenario.\n",
    "def test_resolution_performance(scenario, model_list, num_epochs = 10, trial_seed = 1): \n",
    "    resolution_keys = [64, 128, 224, 384]\n",
    "    performance_dict = dict.fromkeys(resolution_keys)\n",
    "    if scenario == \"Pr_Po_Im\":\n",
    "        imageset = [images_size64_exp5_Pr_Po_Im, images_size128_exp5_Pr_Po_Im, images_size224_exp5_Pr_Po_Im, images_size384_exp5_Pr_Po_Im]\n",
    "    elif scenario == \"Pr_Im\":\n",
    "        imageset = [images_size64_exp5_Pr_Im]#, images_size128_exp5_Pr_Im, images_size224_exp5_Pr_Im, images_size384_exp5_Pr_Im]\n",
    "    elif scenario == \"PrPo_Im\":\n",
    "        imageset = [images_size64_exp5_PrPo_Im, images_size128_exp5_PrPo_Im, images_size224_exp5_PrPo_Im, images_size384_exp5_PrPo_Im]\n",
    "    elif scenario == \"Pr_PoIm\":\n",
    "        imageset = [images_size64_exp5_Pr_PoIm, images_size128_exp5_Pr_PoIm, images_size224_exp5_Pr_PoIm, images_size384_exp5_Pr_PoIm]\n",
    "\n",
    "    k = 0\n",
    "    for resolution_set in imageset:\n",
    "        res_key = resolution_keys[k]\n",
    "        performance_dict[res_key] = {}\n",
    "        \n",
    "        training_images_and_labels, test_images_and_labels = splitData(resolution_set, prop = 0.80, seed_num = trial_seed)\n",
    "        training_images, training_labels = getImageAndLabelArrays(training_images_and_labels)\n",
    "        validation_images, validation_labels = getImageAndLabelArrays(test_images_and_labels)\n",
    "        batch_training_histories = Histories()\n",
    "        # metrics_multiclass = Metrics(validation_images,validation_labels)  TODO\n",
    "        # K.clear_session()\n",
    "        model = model_list[k] # select k'th model from list\n",
    "        reset_weights(model) # re-initialize model weights\n",
    "        model.compile(loss='categorical_crossentropy',  optimizer = \"adam\", metrics = ['accuracy'])\n",
    "        hist = model.fit(training_images, training_labels, batch_size = 32, epochs = num_epochs, verbose=1, validation_data=(validation_images, validation_labels)) #, callbacks=[batch_training_histories])\n",
    "        performance_dict[res_key]['scenario'] = scenario\n",
    "        performance_dict[res_key]['image_size'] = res_key\n",
    "        performance_dict[res_key]['metrics'] = hist\n",
    "        k += 1    \n",
    "    return(performance_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESOLUTION_PERFORMANCE_METRICS_DIR = '../../results/resolution-tests'\n",
    "def main(num_trials = 5):\n",
    "    scenario_list = [\"Pr_Po_Im\", \"Pr_Im\", \"PrPo_Im\", \"Pr_PoIm\"]\n",
    "    optimized_models = [base_model_64, base_model_128, base_model_224, base_model_384] # TO BE UPDATED\n",
    "    scenario_performance_dict = dict.fromkeys(scenario_list)\n",
    "    if not os.path.exists(RESOLUTION_PERFORMANCE_METRICS_DIR): # check if 'tidy/preprocessed_images' subdirectory does not exist\n",
    "        os.makedirs(RESOLUTION_PERFORMANCE_METRICS_DIR) # if not, create it    \n",
    "    for i in range(num_trials):\n",
    "        for j in scenario_list:\n",
    "            scenario_performance_dict[j] = test_resolution_performance(j, optimized_models, num_epochs = 10, trial_seed = 1 + i) #ultimately should be averaged across trials       \n",
    "        scenario_filename = \"resolution_performance_\" + j + \"_trial_\" + str(i) + \".txt\"\n",
    "        with open(os.path.join(RESOLUTION_PERFORMANCE_METRICS_DIR, data_filename), 'w') as file:\n",
    "            file.write(json.dumps(scenario_performance_dict)) # use `json.loads` to do the reverse\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting \n",
    "# p1[64]['metrics'].history['loss']\n",
    "# plt.close('all')\n",
    "# for m in ['recall', 'precision', 'f1-score']:\n",
    "#     for c in [0,1,2]:\n",
    "#         plt.plot(metrics_multiclass.get(m,c), label='Class {0} {1}'.format(c,m))\n",
    "        \n",
    "# plt.legend(loc='lower right')\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
