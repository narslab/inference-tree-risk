{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script explores CNN model performance based on training image resolution.\n",
    "# We test the following training image sizes:\n",
    "# 64 x 64, 128 x 128, 224 x 224, 384 x 384\n",
    "\n",
    "import numpy as np\n",
    "from timeit import default_timer as timer\n",
    "import matplotlib.pyplot as plt\n",
    "import pydot\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "        \n",
    "from sklearn.metrics import recall_score, classification_report\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "import json\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../python/\")\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NUM_CLASS = 2\n",
    "NUM_CHANNELS = 1\n",
    "RESOLUTION_LIST = [64]#, 128, 224, 384]\n",
    "SCENARIO_LIST = [\"Pr_Im\"]#, \"PrPo_Im\", \"Pr_PoIm\", \"Pr_Po_Im\"]\n",
    "\n",
    "NUM_CHANNELS = 1\n",
    "#SCENARIO_LIST = [\"Pr_Po_Im\", \"Pr_Im\", \"PrPo_Im\", \"Pr_PoIm\"]\n",
    "RESOLUTION_PERFORMANCE_METRICS_DIR = '../../results/resolution-tests'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createResolutionScenarioImageDict(resolution_list, scenario_list):\n",
    "    image_dict = dict.fromkeys(resolution_list)\n",
    "    for p in resolution_list:\n",
    "        image_dict[p] = dict.fromkeys(scenario_list)\n",
    "        for s in scenario_list:\n",
    "            image_dict[p][s] = np.load('../../data/tidy/preprocessed_images/size' + str(p) + '_exp5_' + s + '.npy', allow_pickle = True)\n",
    "    return(image_dict)\n",
    "\n",
    "def getOptCNNHyperparams(image_size, scenario):\n",
    "    with open('../../results/optimal-hyperparameters/' + str(image_size) + '/' + scenario + '/hyperparameters.txt') as f: \n",
    "        data = f.read() \n",
    "    opt_params_dict = json.loads(data)   \n",
    "    return(opt_params_dict)\n",
    "\n",
    "def constructBaseCNN(image_size, scenario):\n",
    "    image_shape = (image_size, image_size, NUM_CHANNELS)\n",
    "    p_dict = getOptCNNHyperparams(image_size, scenario)\n",
    "    if scenario==\"Pr_Po_Im\":\n",
    "        num_classes = 3\n",
    "    else:\n",
    "        num_classes = 2\n",
    "    base_model = models.Sequential([\n",
    "        layers.Conv2D(filters = 64, kernel_size = p_dict['kernel_size'], strides = 2, activation=\"relu\", padding=\"same\", input_shape = image_shape),\n",
    "        layers.MaxPooling2D(2),\n",
    "        layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
    "        layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
    "        layers.MaxPooling2D(2),\n",
    "        layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n",
    "        layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n",
    "        layers.MaxPooling2D(2),\n",
    "        layers.Flatten(),\n",
    "        \n",
    "        layers.Dense(p_dict['units_1'], activation = p_dict['activation_1']),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(p_dict['dropout_1']), \n",
    "        \n",
    "        layers.Dense(p_dict['units_2'], activation = p_dict['activation_2']), \n",
    "        layers.Dropout(p_dict['dropout_2']),\n",
    "        \n",
    "        layers.Dense(num_classes, activation=\"softmax\")\n",
    "    ])\n",
    "    return(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_sets = createResolutionScenarioImageDict(RESOLUTION_LIST, SCENARIO_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The resolution test will be conducted scenario by scenario.\n",
    "def testResolutionScenarioPerformance(image_size, scenario, num_epochs = 10, trial_seed = 1):  # opt_params = opt_params_64, \n",
    "    training_images_and_labels, test_images_and_labels = splitData(image_sets[image_size][scenario], prop = 0.80, seed_num = trial_seed)\n",
    "    training_images, training_labels = getImageAndLabelArrays(training_images_and_labels)\n",
    "    validation_images, validation_labels = getImageAndLabelArrays(test_images_and_labels)\n",
    "    # early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "    # batch_training_histories = Histories()\n",
    "    # metrics_multiclass = Metrics(validation_images,validation_labels)  TODO\n",
    "    K.clear_session()\n",
    "    input_shape = (image_size, image_size, NUM_CHANNELS)\n",
    "    model = constructBaseCNN(image_size, scenario)\n",
    "    opt_learning_rate = getOptCNNHyperparams(image_size, scenario)['learning_rate']\n",
    "    reset_weights(model) # re-initialize model weights\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate = opt_learning_rate)\n",
    "    model.compile(loss='categorical_crossentropy',  optimizer = opt, metrics = ['accuracy'])\n",
    "    hist = model.fit(training_images, training_labels, batch_size = 32, epochs = num_epochs, verbose=0, validation_data=(validation_images, validation_labels)) #, callbacks=[batch_training_histories])\n",
    "    performance_dict = {}    \n",
    "    performance_dict['scenario'] = scenario\n",
    "    performance_dict['image_size'] = image_size\n",
    "    performance_dict['metrics'] = hist.history\n",
    "    performance_dict['best_val_accuracy'] = np.max(hist.history['val_accuracy'])\n",
    "    return(performance_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(num_trials = 2):\n",
    "    #scenario_performance_dict = dict.fromkeys(SCENARIO_LIST)\n",
    "    if not os.path.exists(RESOLUTION_PERFORMANCE_METRICS_DIR): # check if 'tidy/preprocessed_images' subdirectory does not exist\n",
    "        os.makedirs(RESOLUTION_PERFORMANCE_METRICS_DIR) # if not, create it    \n",
    "    for s in SCENARIO_LIST:\n",
    "        #scenario_performance_dict[s] = dict.fromkeys(RESOLUTION_LIST)\n",
    "        for p in RESOLUTION_LIST:\n",
    "            for i in range(num_trials):\n",
    "                print(\"Conducting resolution performance test; Scenario: \" + s + \"; Trial: \" + str(i+1))\n",
    "                scenario_performance_dict = testResolutionScenarioPerformance(p, s, num_epochs = 1, trial_seed = 1 + i) #ultimately should be averaged across trials       \n",
    "                scenario_filename = \"scenario_resolution_performance_\" + s + \"_trial_\" + str(i+1) + \".txt\"\n",
    "                hist_filename = \"scenario_resolution_hist_\" + s + \"_trial_\" + str(i+1) + \".txt\"\n",
    "                with open(os.path.join(RESOLUTION_PERFORMANCE_METRICS_DIR, scenario_filename), 'w') as f:\n",
    "                   f.write(json.dumps(scenario_performance_dict )) # use `json.loads` to do the reverse)\n",
    "#                 with open(os.path.join(RESOLUTION_PERFORMANCE_METRICS_DIR, hist_filename), 'w') as g:\n",
    "#                    pickle.dump(history_obj, g ) # use `json.loads` to do the reverse)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conducting resolution performance test; Scenario: Pr_Po_Im; Trial: 1\n",
      "Conducting resolution performance test; Scenario: Pr_Po_Im; Trial: 2\n",
      "Conducting resolution performance test; Scenario: Pr_Im; Trial: 1\n",
      "Conducting resolution performance test; Scenario: Pr_Im; Trial: 2\n",
      "Conducting resolution performance test; Scenario: PrPo_Im; Trial: 1\n",
      "Conducting resolution performance test; Scenario: PrPo_Im; Trial: 2\n",
      "Conducting resolution performance test; Scenario: Pr_PoIm; Trial: 1\n",
      "Conducting resolution performance test; Scenario: Pr_PoIm; Trial: 2\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting \n",
    "# p1[64]['metrics'].history['loss']\n",
    "# plt.close('all')\n",
    "# for m in ['recall', 'precision', 'f1-score']:\n",
    "#     for c in [0,1,2]:\n",
    "#         plt.plot(metrics_multiclass.get(m,c), label='Class {0} {1}'.format(c,m))\n",
    "        \n",
    "# plt.legend(loc='lower right')\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
