{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image # used for loading images\n",
    "import numpy as np\n",
    "import os # used for navigating to image path\n",
    "import imageio # used for writing images\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import pydot\n",
    "from timeit import default_timer as timer\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "\"ResNet 50 dependencies\"\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50 \n",
    "from tensorflow.keras.applications import resnet50\n",
    "\n",
    "\"GoogLeNet dependencies\"\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\"\"\"HP Tuning\"\"\"\n",
    "from kerastuner import HyperModel\n",
    "from kerastuner.tuners import RandomSearch\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "import IPython\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import kerastuner as kt\n",
    "from sklearn import ensemble\n",
    "from sklearn import datasets\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Load numpy output files\"\"\"\n",
    "pr_im_64 = np.load('../../data/tidy/preprocessed_images/size64_exp5_Pr_Im.npy', allow_pickle=True)\n",
    "pr_po_im_64 = np.load('../../data/tidy/preprocessed_images/size64_exp5_Pr_PoIm.npy', allow_pickle=True)\n",
    "pr_po_64 = np.load('../../data/tidy/preprocessed_images/size64_exp5_PrPo_Im.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImageOneHotVector(image_file_name, classification_scenario = \"B\"):\n",
    "    \"\"\"Returns one-hot vector encoding for each image based on specified classification scenario:\n",
    "    Classification Scenario A (3 classes): {probable, possible, improbable}\n",
    "    Classification Scenario B (2 classes): {probable, improbable}\n",
    "    Classification Scenario C (2 classes): {{probable, possible}, improbable}\n",
    "    Classification Scenario D (2 classes): {probable, {possible, improbable}}\n",
    "    \"\"\"\n",
    "    word_label = image_file_name.split('-')[0]\n",
    "    if classification_scenario == \"A\":\n",
    "        if word_label == 'probable' : \n",
    "            return np.array([1, 0, 0])\n",
    "        elif word_label == 'possible' : \n",
    "            return np.array([0, 1, 0])    \n",
    "        elif word_label == 'improbable':\n",
    "            return np.array([0, 0, 1])\n",
    "        else :\n",
    "            return np.array([0, 0, 0]) # if label is not present for current image\n",
    "    elif classification_scenario == \"B\":\n",
    "        if word_label == 'probable' : \n",
    "            return np.array([1, 0])\n",
    "        elif word_label == 'improbable' : \n",
    "            return np.array([0, 1])\n",
    "        else :\n",
    "            return np.array([0, 0]) # if label is not present for current image\n",
    "    elif classification_scenario == \"C\":\n",
    "        if word_label in ['probable', 'possible'] : \n",
    "            return np.array([1, 0])\n",
    "        elif word_label == 'improbable' : \n",
    "            return np.array([0, 1])\n",
    "        else :\n",
    "            return np.array([0, 0]) # if label is not present for current image        \n",
    "    elif classification_scenario == \"D\":\n",
    "        if word_label == 'probable' : \n",
    "            return np.array([1, 0])\n",
    "        elif word_label in ['possible', 'improbable'] : \n",
    "            return np.array([0, 1])\n",
    "        else :\n",
    "            return np.array([0, 0]) # if label is not present for current image        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMG_SIZE = 300\n",
    "NUM_CLASS = 2\n",
    "NUM_CHANNEL = 1\n",
    "CLASSIFICATION_SCENARIO = \"B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMG_SIZE = 300\n",
    "NUM_CLASS = 2\n",
    "NUM_CHANNEL = 1\n",
    "CLASSIFICATION_SCENARIO = \"B\"\n",
    "DIR = '../../data/tidy/labeled_images'\n",
    "def processImageData(img_size, channels=1, l=400,t=0,r=3424,b=3024):    \n",
    "    data = []\n",
    "    image_list = os.listdir(DIR)\n",
    "    for img in image_list:\n",
    "        label = getImageOneHotVector(img, CLASSIFICATION_SCENARIO)\n",
    "        if label.sum() == 0:\n",
    "            continue\n",
    "        path = os.path.join(DIR, img)\n",
    "        img = Image.open(path)\n",
    "        if channels == 1:\n",
    "            img = img.convert('L') # convert image to monochrome \n",
    "            img = img.crop((l, t, r, b)) # after cropping, image size is 3024 x 3024 pixels\n",
    "            #img_size_w, img_size_h = img.size\n",
    "            img = img.resize((img_size, img_size), Image.BICUBIC)\n",
    "            data.append([(np.array(img)/255.).T, label])#scale to 0-1 and transpose\n",
    "#             flip_img = np.fliplr((np.array(img)/255.).T)# Basic Data Augmentation - Horizontal Flipping\n",
    "#             data.append([flip_img, label])#scale to 0-1 and transpose\n",
    "        elif channels == 3:\n",
    "            img = img.crop((l, t, r, b)) # after cropping, image size is 3024 x 3024 pixels  \n",
    "            img = img.resize((img_size, img_size), Image.BICUBIC)\n",
    "            data.append([(np.array(img)/255.).T, label])#scale to 0-1 and transpose            \n",
    "    return (data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitData(image_array, prop = 0.80, seed_num = 111):\n",
    "    \"\"\"Returns training and test arrays of images with specified proportion - prop:1-prop\"\"\"\n",
    "    random.Random(seed_num).shuffle(image_array)\n",
    "    train_size = int(prop*np.shape(image_array)[0])\n",
    "    train = image_array[:train_size]\n",
    "    test = image_array[train_size:]\n",
    "    return(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_image_data = processImageData(108, channels = NUM_CHANNEL)\n",
    "train_data, test_data = splitData(processed_image_data, seed_num = 111) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_data, te_data = splitData(pr_im_64, seed_num = 111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_image_data[202][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(processed_image_data[202][0], cmap = 'gist_gray')\n",
    "#plt.savefig( \"../../figures/image0.png\", dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImageShape(image_array):\n",
    "    if NUM_CHANNEL==1:\n",
    "        image_shape = np.array([np.expand_dims(x[0],axis=2) for x in image_array]).shape[1:4]\n",
    "    elif NUM_CHANNEL==3:\n",
    "        image_shape = np.array([x[0] for x in image_array]).shape[1:4][::-1]\n",
    "    print(image_shape)\n",
    "    return image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image_shape = getImageShape(tr_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model.\n",
    "if NUM_CHANNEL == 1:\n",
    "    train_array = np.array([np.expand_dims(x[0],axis=2) for x in tr_data])\n",
    "    validation_array = np.array([np.expand_dims(x[0],axis=2) for x in te_data])\n",
    "elif NUM_CHANNEL == 3:\n",
    "    train_array = np.array([x[0] for x in tr_data]) \n",
    "    train_array = np.moveaxis(train_array, 1, -1)\n",
    "    validation_array = np.array([x[0] for x in te_data])\n",
    "    validation_array = np.moveaxis(validation_array, 1, -1)\n",
    "\n",
    "train_labels = np.array([x[1] for x in tr_data])\n",
    "validation_labels = np.array([x[1] for x in te_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/keras-team/keras/issues/5400#issuecomment-408743570\n",
    "def check_units(y_true, y_pred):\n",
    "    if y_pred.shape[1] != 1:\n",
    "      y_pred = y_pred[:,1:2]\n",
    "      y_true = y_true[:,1:2]\n",
    "    return y_true, y_pred\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    y_true, y_pred = check_units(y_true, y_pred)\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    y_true, y_pred = check_units(y_true, y_pred)\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    y_true, y_pred = check_units(y_true, y_pred)\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_accuracy(hist):\n",
    "    plt.plot(hist.history[\"accuracy\"])\n",
    "    plt.plot(hist.history[\"val_accuracy\"])\n",
    "    plt.title(\"Model Accuracy\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.legend([\"Train\", \"Validation\"], loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_model_loss(hist):\n",
    "    plt.plot(hist.history[\"loss\"])\n",
    "    plt.plot(hist.history[\"val_loss\"])\n",
    "    plt.title(\"Model Loss\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.legend([\"Train\", \"Validation\"], loc=\"upper right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "# model.compile(loss='categorical_crossentropy', optimizer=opt)\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(filters = 64, kernel_size = 7, strides = 2, activation=\"relu\", padding=\"same\", input_shape = input_image_shape),\n",
    "    layers.MaxPooling2D(2),\n",
    "    layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
    "    layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
    "    layers.MaxPooling2D(2),\n",
    "    layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n",
    "    layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n",
    "    layers.MaxPooling2D(2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation=\"relu\"),\n",
    "    layers.Dropout(0.5), # randomly drop out 50% of the neuorns at each training step\n",
    "    layers.Dense(64, activation=\"relu\"), # flatten all outputs\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(NUM_CLASS, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model.\n",
    "opt = SGD(lr = 0.001) #default learning rate (lr) = 0.1\n",
    "model.compile(loss='categorical_crossentropy',  optimizer = \"adam\",\n",
    "              metrics=[precision,recall, f1, 'accuracy'])\n",
    "\n",
    "start = timer()\n",
    "hist_seq = model.fit(\n",
    "    train_array, train_labels, \n",
    "    batch_size = 32,\n",
    "    epochs = 5,\n",
    "    validation_data=(validation_array, validation_labels)\n",
    ")\n",
    "end = timer()\n",
    "print(end - start) # Time in seconds, e.g. 5.380919524002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_accuracy(hist_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_loss(hist_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HP Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "  model = models.Sequential()\n",
    "  \n",
    "  ## Vary kernel size in first Conv Layer between 5 and 7\n",
    "  hp_k_size = hp.Choice('kernel_size', values = [5, 7])\n",
    "  \n",
    "  # Tune the number of units in the first and second Dense layers\n",
    "  # Choose an optimal value between 32-512\n",
    "  hp_units_l1 = hp.Int('units', min_value = 32, max_value = 512, step = 32)\n",
    "  hp_units_l2 = hp.Int('units', min_value = 32, max_value = 512, step = 32)  \n",
    "    \n",
    "  dropout_rate_a = hp.Float('dropout', min_value = 0.0, max_value = 0.5, step = 0.1)\n",
    "  dropout_rate_b = hp.Float('dropout', min_value = 0.0, max_value = 0.5, step = 0.1)\n",
    "    \n",
    "  # Experiment with \"relu\" and \"tanh\" activation f-ns\n",
    "  hp_dl1_activation = hp.Choice('activation', values = ['relu', 'tanh'])\n",
    "  hp_dl2_activation = hp.Choice('activation', values = ['relu', 'tanh'])\n",
    "    \n",
    "  model.add(layers.Conv2D(filters = 64, kernel_size = hp_k_size, strides = 2, activation=\"relu\", padding=\"same\", input_shape = input_image_shape))\n",
    "\n",
    "  model.add(layers.MaxPooling2D(2))\n",
    "  model.add(layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"))\n",
    "  model.add(layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"))\n",
    "  model.add(layers.MaxPooling2D(2))\n",
    "  model.add(layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"))\n",
    "  model.add(layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"))\n",
    "  model.add(layers.MaxPooling2D(2))\n",
    "  model.add(layers.Flatten())\n",
    "  \n",
    "  \n",
    "  model.add(layers.Dense(units = hp_units_l1, activation = hp_dl1_activation))\n",
    "  model.add(layers.BatchNormalization()) # Networks train faster & converge much more quickly\n",
    "  model.add(layers.Dropout(dropout_rate_a))\n",
    "  model.add(layers.Dense(units = hp_units_l2, activation = hp_dl2_activation))\n",
    "  model.add(layers.Dropout(dropout_rate_b))\n",
    "  model.add(keras.layers.Dense(NUM_CLASS, activation='softmax'))\n",
    "    \n",
    "  # Tune the learning rate for the optimizer \n",
    "  # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "  hp_learning_rate = hp.Choice('learning_rate', values = [1e-2, 1e-3, 1e-4]) \n",
    "  model.compile(optimizer = keras.optimizers.Adam(learning_rate = hp_learning_rate),\n",
    "                loss = keras.losses.CategoricalCrossentropy(from_logits = True), #keras.losses.SparseCategoricalCrossentropy(from_logits = True)\n",
    "                metrics = ['accuracy'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective = 'val_loss', \n",
    "                     max_epochs = 10,\n",
    "                     factor = 3,\n",
    "                     directory = 'my_dir',\n",
    "                     project_name = 'intro_to_kt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClearTrainingOutput(tf.keras.callbacks.Callback):\n",
    "  def on_train_end(*args, **kwargs):\n",
    "    IPython.display.clear_output(wait = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(train_array, train_labels, epochs = 10, validation_data = (validation_array, validation_labels), callbacks = [ClearTrainingOutput()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the optimal hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials = 10)[0]\n",
    "\n",
    "#Best Hperparamter summary\n",
    "best_hps_summary = f\"\"\"\n",
    "The hyperparameter search for classification scenario {CLASSIFICATION_SCENARIO} is complete. The optimal number of units in the first densely-connected\n",
    "layer is {best_hps.get('units')}. The optimal learning rate for the optimizer\n",
    "is {best_hps.get('learning_rate')}. The optimal kernel size of the first convolution layer is {best_hps.get('kernel_size')}.\n",
    "The optimal dropout rate for the optimizer is {best_hps.get('dropout')}. The optimal activation layer for the optimizer is {best_hps.get('activation')}.\n",
    "\"\"\"\n",
    "print(best_hps_summary,  file=open('../../results/models/best_hyperparameters_scenario_b.txt', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Return best hyperparameter dictionary\n",
    "best_hps_dict = tuner.get_best_hyperparameters()[0].values\n",
    "best_hps_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tuner.get_best_models(num_models=1)[0]\n",
    "model.summary()\n",
    "model.save('../../results/models/optimized_scenario_b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', metrics=[precision,recall, f1, 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "model.fit(train_array, train_labels, epochs=10, validation_data=(validation_array, validation_labels))\n",
    "end = timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_model = tuner.get_best_models(num_models=1)[0]\n",
    "model.evaluate(train_array, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#loss, acc = model.evaluate(testImages, testLabels, verbose = 0)\n",
    "#print(acc * 100)\n",
    "y_pred = model.predict(validation_array, batch_size=32, verbose=1)\n",
    "y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "\n",
    "#print(classification_report(validation_labels, y_pred_bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, \"../../figures/cnn-model1.png\", expand_nested = False, rankdir = \"TB\", show_shapes=True, dpi=192)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet 34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualUnit(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters, strides=1, activation=\"relu\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.activation = tf.keras.activations.get(activation)\n",
    "        self.main_layers = [\n",
    "            tf.keras.layers.Conv2D(filters, 3, strides=strides, padding=\"same\", use_bias=False),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Conv2D(filters, 3, strides=1, padding=\"same\", use_bias=False),\n",
    "            tf.keras.layers.BatchNormalization()\n",
    "        ]\n",
    "        self.skip_layers = []\n",
    "        if strides > 1:\n",
    "            self.skip_layers = [\n",
    "                tf.keras.layers.Conv2D(filters, 1, strides=strides, padding=\"same\", use_bias=False),    \n",
    "                tf.keras.layers.BatchNormalization()\n",
    "            ]\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        Z = inputs\n",
    "        for layer in self.main_layers:\n",
    "            Z = layer(Z)\n",
    "        skip_Z = inputs\n",
    "        for layer in self.skip_layers:\n",
    "            skip_Z = layer(skip_Z)\n",
    "        return self.activation(Z + skip_Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet34mod = tf.keras.models.Sequential()\n",
    "resnet34mod.add(tf.keras.layers.Conv2D(64, 7, strides=2, input_shape=input_image_shape, padding=\"same\", use_bias=False))\n",
    "resnet34mod.add(tf.keras.layers.BatchNormalization())\n",
    "resnet34mod.add(tf.keras.layers.Activation(\"relu\"))\n",
    "resnet34mod.add(tf.keras.layers.MaxPool2D(pool_size=3, strides=2, padding=\"same\"))\n",
    "prev_filters = 64\n",
    "for filters in [64] * 3 + [128] * 4 + [256] * 6 + [512] * 3:\n",
    "    strides = 1 if filters == prev_filters else 2\n",
    "    resnet34mod.add(ResidualUnit(filters, strides=strides))\n",
    "    prev_filters = filters\n",
    "resnet34mod.add(tf.keras.layers.GlobalAvgPool2D())\n",
    "resnet34mod.add(tf.keras.layers.Flatten())\n",
    "resnet34mod.add(tf.keras.layers.Flatten())\n",
    "resnet34mod.add(tf.keras.layers.Dense(NUM_CLASS, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet34mod.compile(loss='binary_crossentropy',  optimizer = \"adam\",# metrics=[ 'accuracy']) #tf.keras.metrics.SpecificityAtSensitivity(0.5), tf.keras.metrics.SensitivityAtSpecificity(0.5), \n",
    "              metrics=[precision,recall, f1, 'accuracy']) #metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "start = timer()\n",
    "resnet34mod.fit(\n",
    "    train_array, train_labels, \n",
    "    batch_size = 32,\n",
    "    epochs = 4,\n",
    "    validation_data=(validation_array, validation_labels)\n",
    ")\n",
    "end = timer()\n",
    "print(end - start) # Time in seconds, e.g. 5.380919524002"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\"Define ResNet 50 model instance (Keras built-in)\"\n",
    "rn50 = resnet50.ResNet50(include_top=True, \n",
    "                           weights=None, \n",
    "                           input_tensor=None, \n",
    "                           input_shape=input_image_shape, \n",
    "                           pooling= 'max', \n",
    "                           classes=2)\n",
    "\n",
    "rn50.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Configure the model with losses and metrics\"\n",
    "rn50.compile(loss='categorical_crossentropy',  optimizer = \"adam\",\n",
    "              metrics=[precision,recall, f1, 'accuracy']) \n",
    "\n",
    "start = timer()\n",
    "\n",
    "\"Fit ResNet 50 to data\"\n",
    "hist_rn50 = rn50.fit(\n",
    "    train_array, train_labels, \n",
    "    batch_size = 32,\n",
    "    epochs = 5,\n",
    "    validation_data=(validation_array, validation_labels)\n",
    ")\n",
    "\n",
    "end = timer()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_accuracy(hist_rn50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_loss(hist_rn50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GoogLeNet\n",
    "### InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Instantiate the Inception v3 architecture\"\"\"\n",
    "iv3 = tf.keras.applications.InceptionV3(\n",
    "    include_top=True,\n",
    "    weights=None,\n",
    "    input_tensor=None,\n",
    "    input_shape=input_image_shape,\n",
    "    pooling='avg',\n",
    "    classes=2,\n",
    "    classifier_activation=\"softmax\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Configure the model with losses and metrics\"\n",
    "iv3.compile(loss='categorical_crossentropy',  optimizer = \"adam\",\n",
    "              metrics=[precision,recall, f1, 'accuracy']) \n",
    "\n",
    "start = timer()\n",
    "\n",
    "\"Fit Inception v3 to data\"\n",
    "hist_iv3 = iv3.fit(\n",
    "    train_array, train_labels, \n",
    "    batch_size = 32,\n",
    "    epochs = 10,\n",
    "    validation_data=(validation_array, validation_labels)\n",
    ")\n",
    "\n",
    "end = timer()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_accuracy(hist_iv3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_loss(hist_iv3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
