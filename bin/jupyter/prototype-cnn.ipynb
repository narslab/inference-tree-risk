{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image # used for loading images\n",
    "import numpy as np\n",
    "import os # used for navigating to image path\n",
    "import imageio # used for writing images\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import pydot\n",
    "from timeit import default_timer as timer\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "\"ResNet 50 dependencies\"\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50 \n",
    "from tensorflow.keras.applications import resnet50\n",
    "\n",
    "\"GoogLeNet dependencies\"\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImageOneHotVector(image_file_name, classification_scenario = \"B\"):\n",
    "    \"\"\"Returns one-hot vector encoding for each image based on specified classification scenario:\n",
    "    Classification Scenario A (3 classes): {probable, possible, improbable}\n",
    "    Classification Scenario B (2 classes): {probable, improbable}\n",
    "    Classification Scenario C (2 classes): {{probable, possible}, improbable}\n",
    "    Classification Scenario D (2 classes): {probable, {possible, improbable}}\n",
    "    \"\"\"\n",
    "    word_label = image_file_name.split('-')[0]\n",
    "    if classification_scenario == \"A\":\n",
    "        if word_label == 'probable' : \n",
    "            return np.array([1, 0, 0])\n",
    "        elif word_label == 'possible' : \n",
    "            return np.array([0, 1, 0])    \n",
    "        elif word_label == 'improbable':\n",
    "            return np.array([0, 0, 1])\n",
    "        else :\n",
    "            return np.array([0, 0, 0]) # if label is not present for current image\n",
    "    elif classification_scenario == \"B\":\n",
    "        if word_label == 'probable' : \n",
    "            return np.array([1, 0])\n",
    "        elif word_label == 'improbable' : \n",
    "            return np.array([0, 1])\n",
    "        else :\n",
    "            return np.array([0, 0]) # if label is not present for current image\n",
    "    elif classification_scenario == \"C\":\n",
    "        if word_label in ['probable', 'possible'] : \n",
    "            return np.array([1, 0])\n",
    "        elif word_label == 'improbable' : \n",
    "            return np.array([0, 1])\n",
    "        else :\n",
    "            return np.array([0, 0]) # if label is not present for current image        \n",
    "    elif classification_scenario == \"D\":\n",
    "        if word_label == 'probable' : \n",
    "            return np.array([1, 0])\n",
    "        elif word_label in ['possible', 'improbable'] : \n",
    "            return np.array([0, 1])\n",
    "        else :\n",
    "            return np.array([0, 0]) # if label is not present for current image        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMG_SIZE = 300\n",
    "NUM_CLASS = 2\n",
    "NUM_CHANNEL = 1\n",
    "CLASSIFICATION_SCENARIO = \"B\"\n",
    "DIR = '../../data/tidy/labeled_images'\n",
    "def processImageData(img_size, channels=1, l=400,t=0,r=3424,b=3024):    \n",
    "    data = []\n",
    "    image_list = os.listdir(DIR)\n",
    "    for img in image_list:\n",
    "        label = getImageOneHotVector(img, CLASSIFICATION_SCENARIO)\n",
    "        if label.sum() == 0:\n",
    "            continue\n",
    "        path = os.path.join(DIR, img)\n",
    "        img = Image.open(path)\n",
    "        if channels == 1:\n",
    "            img = img.convert('L') # convert image to monochrome \n",
    "            img = img.crop((l, t, r, b)) # after cropping, image size is 3024 x 3024 pixels\n",
    "            #img_size_w, img_size_h = img.size\n",
    "            img = img.resize((img_size, img_size), Image.BICUBIC)\n",
    "            data.append([(np.array(img)/255.).T, label])#scale to 0-1 and transpose\n",
    "#             flip_img = np.fliplr((np.array(img)/255.).T)# Basic Data Augmentation - Horizontal Flipping\n",
    "#             data.append([flip_img, label])#scale to 0-1 and transpose\n",
    "        elif channels == 3:\n",
    "            img = img.crop((l, t, r, b)) # after cropping, image size is 3024 x 3024 pixels  \n",
    "            img = img.resize((img_size, img_size), Image.BICUBIC)\n",
    "            data.append([(np.array(img)/255.).T, label])#scale to 0-1 and transpose            \n",
    "    return (data)\n",
    "\n",
    "def splitData(image_array, prop = 0.80, seed_num = 111):\n",
    "    \"\"\"Returns training and test arrays of images with specified proportion - prop:1-prop\"\"\"\n",
    "    random.Random(seed_num).shuffle(image_array)\n",
    "    train_size = int(prop*np.shape(image_array)[0])\n",
    "    train = image_array[:train_size]\n",
    "    test = image_array[train_size:]\n",
    "    return(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_image_data = processImageData(108, channels = NUM_CHANNEL)\n",
    "train_data, test_data = splitData(processed_image_data, seed_num = 111) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_image_data[202][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(processed_image_data[202][0], cmap = 'gist_gray')\n",
    "#plt.savefig( \"../../figures/image0.png\", dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImageShape(image_array):\n",
    "    if NUM_CHANNEL==1:\n",
    "        image_shape = np.array([np.expand_dims(x[0],axis=2) for x in image_array]).shape[1:4]\n",
    "    elif NUM_CHANNEL==3:\n",
    "        image_shape = np.array([x[0] for x in image_array]).shape[1:4][::-1]\n",
    "    print(image_shape)\n",
    "    return image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image_shape = getImageShape(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model.\n",
    "if NUM_CHANNEL == 1:\n",
    "    train_array = np.array([np.expand_dims(x[0],axis=2) for x in train_data])\n",
    "    validation_array = np.array([np.expand_dims(x[0],axis=2) for x in test_data])\n",
    "elif NUM_CHANNEL == 3:\n",
    "    train_array = np.array([x[0] for x in train_data]) \n",
    "    train_array = np.moveaxis(train_array, 1, -1)\n",
    "    validation_array = np.array([x[0] for x in test_data])\n",
    "    validation_array = np.moveaxis(validation_array, 1, -1)\n",
    "\n",
    "train_labels = np.array([x[1] for x in train_data])\n",
    "validation_labels = np.array([x[1] for x in test_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_labels)\n",
    "validation_array.shape\n",
    "train_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/keras-team/keras/issues/5400#issuecomment-408743570\n",
    "def check_units(y_true, y_pred):\n",
    "    if y_pred.shape[1] != 1:\n",
    "      y_pred = y_pred[:,1:2]\n",
    "      y_true = y_true[:,1:2]\n",
    "    return y_true, y_pred\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    y_true, y_pred = check_units(y_true, y_pred)\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    y_true, y_pred = check_units(y_true, y_pred)\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    y_true, y_pred = check_units(y_true, y_pred)\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential([\n",
    "    layers.Conv2D(filters = 64, kernel_size = 7, strides = 2, activation=\"relu\", padding=\"same\", input_shape = input_image_shape),\n",
    "    layers.MaxPooling2D(2),\n",
    "    layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
    "    layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
    "    layers.MaxPooling2D(2),\n",
    "    layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n",
    "    layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n",
    "    layers.MaxPooling2D(2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation=\"relu\"),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(NUM_CLASS, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# Compile the model.\n",
    "opt = SGD(lr = 0.001) #default learning rate (lr) = 0.1\n",
    "model.compile(loss='categorical_crossentropy',  optimizer = \"adam\",\n",
    "              metrics=[precision,recall, f1, 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "model.fit(\n",
    "    train_array, train_labels, \n",
    "    batch_size = 32,\n",
    "    epochs = 5,\n",
    "    validation_data=(validation_array, validation_labels)\n",
    ")\n",
    "end = timer()\n",
    "print(end - start) # Time in seconds, e.g. 5.380919524002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#loss, acc = model.evaluate(testImages, testLabels, verbose = 0)\n",
    "#print(acc * 100)\n",
    "y_pred = model.predict(validation_array, batch_size=32, verbose=1)\n",
    "y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "\n",
    "#print(classification_report(validation_labels, y_pred_bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, \"../../figures/cnn-model1.png\", expand_nested = False, rankdir = \"TB\", show_shapes=True, dpi=192)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualUnit(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters, strides=1, activation=\"relu\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.activation = tf.keras.activations.get(activation)\n",
    "        self.main_layers = [\n",
    "            tf.keras.layers.Conv2D(filters, 3, strides=strides, padding=\"same\", use_bias=False),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Conv2D(filters, 3, strides=1, padding=\"same\", use_bias=False),\n",
    "            tf.keras.layers.BatchNormalization()\n",
    "        ]\n",
    "        self.skip_layers = []\n",
    "        if strides > 1:\n",
    "            self.skip_layers = [\n",
    "                tf.keras.layers.Conv2D(filters, 1, strides=strides, padding=\"same\", use_bias=False),    \n",
    "                tf.keras.layers.BatchNormalization()\n",
    "            ]\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        Z = inputs\n",
    "        for layer in self.main_layers:\n",
    "            Z = layer(Z)\n",
    "        skip_Z = inputs\n",
    "        for layer in self.skip_layers:\n",
    "            skip_Z = layer(skip_Z)\n",
    "        return self.activation(Z + skip_Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet34mod = tf.keras.models.Sequential()\n",
    "resnet34mod.add(tf.keras.layers.Conv2D(64, 7, strides=2, input_shape=input_image_shape, padding=\"same\", use_bias=False))\n",
    "resnet34mod.add(tf.keras.layers.BatchNormalization())\n",
    "resnet34mod.add(tf.keras.layers.Activation(\"relu\"))\n",
    "resnet34mod.add(tf.keras.layers.MaxPool2D(pool_size=3, strides=2, padding=\"same\"))\n",
    "prev_filters = 64\n",
    "for filters in [64] * 3 + [128] * 4 + [256] * 6 + [512] * 3:\n",
    "    strides = 1 if filters == prev_filters else 2\n",
    "    resnet34mod.add(ResidualUnit(filters, strides=strides))\n",
    "    prev_filters = filters\n",
    "resnet34mod.add(tf.keras.layers.GlobalAvgPool2D())\n",
    "resnet34mod.add(tf.keras.layers.Flatten())\n",
    "resnet34mod.add(tf.keras.layers.Flatten())\n",
    "resnet34mod.add(tf.keras.layers.Dense(NUM_CLASS, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet34mod.compile(loss='binary_crossentropy',  optimizer = \"adam\",# metrics=[ 'accuracy']) #tf.keras.metrics.SpecificityAtSensitivity(0.5), tf.keras.metrics.SensitivityAtSpecificity(0.5), \n",
    "              metrics=[precision,recall, f1, 'accuracy']) #metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "start = timer()\n",
    "resnet34mod.fit(\n",
    "    train_array, train_labels, \n",
    "    batch_size = 32,\n",
    "    epochs = 4,\n",
    "    validation_data=(validation_array, validation_labels)\n",
    ")\n",
    "end = timer()\n",
    "print(end - start) # Time in seconds, e.g. 5.380919524002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\"Define ResNet 50 model instance (Keras built-in)\"\n",
    "rn50 = resnet50.ResNet50(include_top=True, \n",
    "                           weights=None, \n",
    "                           input_tensor=None, \n",
    "                           input_shape=input_image_shape, \n",
    "                           pooling= 'max', \n",
    "                           classes=2)\n",
    "\n",
    "rn50.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Configure the model with losses and metrics\"\n",
    "rn50.compile(loss='categorical_crossentropy',  optimizer = \"adam\",\n",
    "              metrics=[precision,recall, f1, 'accuracy']) \n",
    "\n",
    "start = timer()\n",
    "\n",
    "\"Fit ResNet 50 to data\"\n",
    "rn50.fit(\n",
    "    train_array, train_labels, \n",
    "    batch_size = 32,\n",
    "    epochs = 5,\n",
    "    validation_data=(validation_array, validation_labels)\n",
    ")\n",
    "\n",
    "end = timer()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GoogLeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "def inception(x, filters):\n",
    "    # 1x1\n",
    "    path1 = Conv2D(filters=filters[0], kernel_size=(1,1), strides=1, padding='same', activation='relu')(x)\n",
    "\n",
    "    # 1x1->3x3\n",
    "    path2 = Conv2D(filters=filters[1][0], kernel_size=(1,1), strides=1, padding='same', activation='relu')(x)\n",
    "    path2 = Conv2D(filters=filters[1][1], kernel_size=(3,3), strides=1, padding='same', activation='relu')(path2)\n",
    "    \n",
    "    # 1x1->5x5\n",
    "    path3 = Conv2D(filters=filters[2][0], kernel_size=(1,1), strides=1, padding='same', activation='relu')(x)\n",
    "    path3 = Conv2D(filters=filters[2][1], kernel_size=(5,5), strides=1, padding='same', activation='relu')(path3)\n",
    "\n",
    "    # 3x3->1x1\n",
    "    path4 = MaxPooling2D(pool_size=(3,3), strides=1, padding='same')(x)\n",
    "    path4 = Conv2D(filters=filters[3], kernel_size=(1,1), strides=1, padding='same', activation='relu')(path4)\n",
    "\n",
    "    return Concatenate(axis=-1)([path1,path2,path3,path4])\n",
    "\n",
    "\n",
    "def auxiliary(x, name=None):\n",
    "    layer = AveragePooling2D(pool_size=(5,5), strides=3, padding='valid')(x)\n",
    "    layer = Conv2D(filters=128, kernel_size=(1,1), strides=1, padding='same', activation='relu')(layer)\n",
    "    layer = Flatten()(layer)\n",
    "    layer = Dense(units=256, activation='relu')(layer)\n",
    "    layer = Dropout(0.4)(layer)\n",
    "    layer = Dense(units=NUM_CLASS, activation='softmax', name=name)(layer) \n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def googlenet():\n",
    "    layer_in = Input(shape=input_image_shape)\n",
    "    \n",
    "    # stage-1\n",
    "    layer = Conv2D(filters=64, kernel_size=(7,7), strides=2, padding='same', activation='relu')(layer_in)\n",
    "    layer = MaxPooling2D(pool_size=(3,3), strides=2, padding='same')(layer)\n",
    "    layer = BatchNormalization()(layer)\n",
    "\n",
    "    # stage-2\n",
    "    layer = Conv2D(filters=64, kernel_size=(1,1), strides=1, padding='same', activation='relu')(layer)\n",
    "    layer = Conv2D(filters=192, kernel_size=(3,3), strides=1, padding='same', activation='relu')(layer)\n",
    "    layer = BatchNormalization()(layer)\n",
    "    layer = MaxPooling2D(pool_size=(3,3), strides=2, padding='same')(layer)\n",
    "\n",
    "    # stage-3\n",
    "    layer = inception(layer, [ 64,  (96,128), (16,32), 32]) #3a\n",
    "    layer = inception(layer, [128, (128,192), (32,96), 64]) #3b\n",
    "    layer = MaxPooling2D(pool_size=(3,3), strides=2, padding='same')(layer)\n",
    "    \n",
    "    # stage-4\n",
    "    layer = inception(layer, [192,  (96,208),  (16,48),  64]) #4a\n",
    "    aux1  = auxiliary(layer, name='aux1')\n",
    "    layer = inception(layer, [160, (112,224),  (24,64),  64]) #4b\n",
    "    layer = inception(layer, [128, (128,256),  (24,64),  64]) #4c\n",
    "    layer = inception(layer, [112, (144,288),  (32,64),  64]) #4d\n",
    "    aux2  = auxiliary(layer, name='aux2')\n",
    "    layer = inception(layer, [256, (160,320), (32,128), 128]) #4e\n",
    "    layer = MaxPooling2D(pool_size=(3,3), strides=2, padding='same')(layer)\n",
    "    \n",
    "    # stage-5\n",
    "    layer = inception(layer, [256, (160,320), (32,128), 128]) #5a\n",
    "    layer = inception(layer, [384, (192,384), (48,128), 128]) #5b\n",
    "    #layer = AveragePooling2D(pool_size=(7,7), strides=1, padding='valid')(layer)\n",
    "    \n",
    "    # stage-6\n",
    "    layer = Flatten()(layer)\n",
    "    layer = Dropout(0.4)(layer)\n",
    "    layer = Dense(units=256, activation='linear')(layer)\n",
    "    main = Dense(units=NUM_CLASS, activation='sigmoid', name='main')(layer)\n",
    "    \n",
    "    model = Model(inputs=layer_in, outputs=[main, aux1, aux2])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train model\n",
    "gglnet = googlenet()\n",
    "gglnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "gglnet.compile(loss='categorical_crossentropy',  optimizer = \"adam\",\n",
    "              metrics=[precision,recall, f1, 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = timer()\n",
    "\n",
    "gglnet.fit(\n",
    "    train_array, train_labels, \n",
    "    batch_size = 32,\n",
    "    epochs = 5,\n",
    "    validation_data=(validation_array, validation_labels)\n",
    ")\n",
    "\n",
    "end = timer()\n",
    "\n",
    "print(end - start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
