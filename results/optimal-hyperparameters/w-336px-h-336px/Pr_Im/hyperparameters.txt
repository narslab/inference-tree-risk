{"kernel_size": 7, "units_1": 320, "units_2": 160, "dropout_1": 0.4, "dropout_2": 0.30000000000000004, "activation_1": "tanh", "activation_2": "relu", "learning_rate": 8.4301773168236e-05, "tuner/epochs": 12, "tuner/initial_epoch": 0, "tuner/bracket": 0, "tuner/round": 0}