{"kernel_size": 5, "units_1": 384, "units_2": 256, "dropout_1": 0.25, "dropout_2": 0.35000000000000003, "activation_1": "tanh", "activation_2": "relu", "learning_rate": 0.00010913747652406281, "tuner/epochs": 10, "tuner/initial_epoch": 0, "tuner/bracket": 0, "tuner/round": 0}